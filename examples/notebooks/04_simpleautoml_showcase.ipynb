{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPY: SimpleAutoML Showcase\n",
    "\n",
    "Este notebook demuestra las capacidades de **SimpleAutoML**, el sistema de AutoML integrado en MLPY que:\n",
    "- Detecta automÃ¡ticamente el tipo de tarea\n",
    "- Optimiza modelos y preprocesamiento\n",
    "- Realiza feature engineering automÃ¡tico\n",
    "- Proporciona resultados interpretables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, load_diabetes, make_classification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar MLPY SimpleAutoML\n",
    "from mlpy.automl import SimpleAutoML\n",
    "from mlpy.tasks import TaskClassif, TaskRegr\n",
    "from mlpy.measures import MeasureClassifAccuracy, MeasureRegrMSE\n",
    "\n",
    "print(\"âœ… SimpleAutoML importado correctamente\")\n",
    "print(\"ðŸš€ MLPY AutoML estÃ¡ listo para usar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ejemplo BÃ¡sico: ClasificaciÃ³n con Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset Wine\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_df['wine_type'] = wine.target\n",
    "\n",
    "print(f\"Wine Dataset: {wine_df.shape}\")\n",
    "print(f\"Features: {len(wine.feature_names)}\")\n",
    "print(f\"Clases: {np.unique(wine_df['wine_type'])}\")\n",
    "print(f\"\\nDistribuciÃ³n de clases:\")\n",
    "print(wine_df['wine_type'].value_counts().sort_index())\n",
    "\n",
    "# Vista previa\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear SimpleAutoML para clasificaciÃ³n\n",
    "automl_classif = SimpleAutoML(\n",
    "    time_limit=120,  # 2 minutos\n",
    "    max_models=10,   # MÃ¡ximo 10 modelos\n",
    "    feature_engineering=True,\n",
    "    feature_selection=True,\n",
    "    cross_validation=5,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ðŸŽ¯ ConfiguraciÃ³n de AutoML:\")\n",
    "print(f\"   - LÃ­mite de tiempo: {automl_classif.time_limit}s\")\n",
    "print(f\"   - MÃ¡ximo de modelos: {automl_classif.max_models}\")\n",
    "print(f\"   - Feature engineering: {automl_classif.feature_engineering}\")\n",
    "print(f\"   - Feature selection: {automl_classif.feature_selection}\")\n",
    "print(f\"   - Cross-validation: {automl_classif.cross_validation} folds\")\n",
    "\n",
    "# Ejecutar AutoML\n",
    "print(\"\\nðŸš€ Iniciando bÃºsqueda automÃ¡tica...\")\n",
    "result_wine = automl_classif.fit(wine_df, 'wine_type')\n",
    "\n",
    "print(f\"\\nðŸ† RESULTADOS FINALES:\")\n",
    "print(f\"   ðŸ“Š Mejor accuracy: {result_wine.best_score:.4f}\")\n",
    "print(f\"   â±ï¸  Tiempo total: {result_wine.training_time:.1f}s\")\n",
    "print(f\"   ðŸ” Modelos evaluados: {len(result_wine.leaderboard)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar los resultados\n",
    "print(\"ðŸ“‹ LEADERBOARD (Top 5 modelos):\")\n",
    "print(\"=\"*60)\n",
    "top_models = result_wine.leaderboard.head()\n",
    "for idx, row in top_models.iterrows():\n",
    "    print(f\"{idx+1}. {row['model']:25s} Score: {row['score']:.4f}\")\n",
    "\n",
    "# Leaderboard completo\n",
    "print(\"\\nðŸ“Š Leaderboard completo:\")\n",
    "print(result_wine.leaderboard.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones con el mejor modelo\n",
    "print(\"ðŸ”® Probando predicciones con el mejor modelo:\")\n",
    "\n",
    "# Tomar una muestra de datos para predecir\n",
    "sample_data = wine_df.drop('wine_type', axis=1).sample(5, random_state=42)\n",
    "real_labels = wine_df.loc[sample_data.index, 'wine_type'].values\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = result_wine.predict(sample_data)\n",
    "\n",
    "print(\"\\nComparaciÃ³n PredicciÃ³n vs Real:\")\n",
    "print(\"-\" * 35)\n",
    "for i, (pred, real) in enumerate(zip(predictions.response, real_labels)):\n",
    "    status = \"âœ…\" if pred == real else \"âŒ\"\n",
    "    print(f\"Muestra {i+1}: {pred} vs {real} {status}\")\n",
    "\n",
    "accuracy = np.mean(predictions.response == real_labels)\n",
    "print(f\"\\nAccuracy en muestra: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ejemplo de RegresiÃ³n: Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset Diabetes\n",
    "diabetes = load_diabetes()\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "print(f\"Diabetes Dataset: {diabetes_df.shape}\")\n",
    "print(f\"Target range: {diabetes_df['progression'].min():.1f} - {diabetes_df['progression'].max():.1f}\")\n",
    "print(f\"Target mean: {diabetes_df['progression'].mean():.1f}\")\n",
    "\n",
    "# Vista previa\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML para regresiÃ³n\n",
    "automl_regr = SimpleAutoML(\n",
    "    time_limit=90,   # 1.5 minutos\n",
    "    max_models=8,\n",
    "    feature_engineering=True,\n",
    "    feature_selection=False,  # Dataset pequeÃ±o, no necesario\n",
    "    cross_validation=5,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ðŸŽ¯ ConfiguraciÃ³n para RegresiÃ³n:\")\n",
    "print(f\"   - Tarea: RegresiÃ³n (detectada automÃ¡ticamente)\")\n",
    "print(f\"   - Feature selection: {automl_regr.feature_selection}\")\n",
    "print(f\"   - Test size: {automl_regr.test_size}\")\n",
    "\n",
    "# Ejecutar AutoML - especificamos que es regresiÃ³n\n",
    "print(\"\\nðŸš€ Iniciando AutoML para regresiÃ³n...\")\n",
    "result_diabetes = automl_regr.fit(\n",
    "    diabetes_df, \n",
    "    'progression',\n",
    "    task_type='regression'  # ExplÃ­citamente especificamos regresiÃ³n\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ† RESULTADOS DE REGRESIÃ“N:\")\n",
    "print(f\"   ðŸ“Š Mejor MSE: {result_diabetes.best_score:.2f}\")\n",
    "print(f\"   ðŸ“Š RMSE: {np.sqrt(result_diabetes.best_score):.2f}\")\n",
    "print(f\"   â±ï¸  Tiempo: {result_diabetes.training_time:.1f}s\")\n",
    "print(f\"   ðŸ” Modelos: {len(result_diabetes.leaderboard)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar resultados de regresiÃ³n\n",
    "print(\"ðŸ“‹ LEADERBOARD REGRESIÃ“N (Top 5):\")\n",
    "print(\"=\"*70)\n",
    "top_regr = result_diabetes.leaderboard.head()\n",
    "for idx, row in top_regr.iterrows():\n",
    "    rmse = np.sqrt(row['score'])\n",
    "    print(f\"{idx+1}. {row['model']:25s} MSE: {row['score']:.2f}  RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Hacer predicciones\n",
    "print(\"\\nðŸ”® Predicciones de regresiÃ³n:\")\n",
    "sample_regr = diabetes_df.drop('progression', axis=1).sample(5, random_state=123)\n",
    "real_values = diabetes_df.loc[sample_regr.index, 'progression'].values\n",
    "\n",
    "predictions_regr = result_diabetes.predict(sample_regr)\n",
    "\n",
    "print(\"\\nComparaciÃ³n PredicciÃ³n vs Real:\")\n",
    "print(\"-\" * 45)\n",
    "for i, (pred, real) in enumerate(zip(predictions_regr.response, real_values)):\n",
    "    error = abs(pred - real)\n",
    "    print(f\"Muestra {i+1}: {pred:6.1f} vs {real:6.1f} (error: {error:5.1f})\")\n",
    "\n",
    "mae = np.mean(np.abs(predictions_regr.response - real_values))\n",
    "print(f\"\\nMAE en muestra: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ejemplo con Dataset Personalizado (DetecciÃ³n AutomÃ¡tica de Tarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset sintÃ©tico con caracterÃ­sticas mixtas\n",
    "np.random.seed(42)\n",
    "n_samples = 800\n",
    "\n",
    "# Features numÃ©ricas\n",
    "numeric_features = np.random.randn(n_samples, 8)\n",
    "\n",
    "# Features categÃ³ricas\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "cat_feature1 = np.random.choice(categories, n_samples)\n",
    "cat_feature2 = np.random.choice(['High', 'Medium', 'Low'], n_samples)\n",
    "\n",
    "# Crear DataFrame\n",
    "custom_df = pd.DataFrame(numeric_features, columns=[f'num_feat_{i}' for i in range(8)])\n",
    "custom_df['category_1'] = cat_feature1\n",
    "custom_df['category_2'] = cat_feature2\n",
    "\n",
    "# Crear target basado en algunas features (clasificaciÃ³n)\n",
    "target_score = (\n",
    "    2 * custom_df['num_feat_0'] + \n",
    "    1.5 * custom_df['num_feat_1'] - \n",
    "    0.8 * custom_df['num_feat_2'] +\n",
    "    (custom_df['category_1'] == 'A').astype(int) * 1.2 +\n",
    "    np.random.normal(0, 0.5, n_samples)\n",
    ")\n",
    "\n",
    "# Convertir a clases binarias\n",
    "custom_df['target'] = (target_score > target_score.median()).astype(int)\n",
    "\n",
    "# Introducir algunos valores faltantes\n",
    "missing_mask = np.random.random(custom_df.shape) < 0.03  # 3% missing\n",
    "custom_df = custom_df.mask(missing_mask)\n",
    "\n",
    "print(f\"Dataset personalizado: {custom_df.shape}\")\n",
    "print(f\"Features numÃ©ricas: 8\")\n",
    "print(f\"Features categÃ³ricas: 2\")\n",
    "print(f\"Valores faltantes: {custom_df.isnull().sum().sum()}\")\n",
    "print(f\"DistribuciÃ³n target: {custom_df['target'].value_counts().to_dict()}\")\n",
    "\n",
    "# Vista previa\n",
    "custom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML con detecciÃ³n automÃ¡tica\n",
    "automl_custom = SimpleAutoML(\n",
    "    time_limit=150,  # MÃ¡s tiempo por la complejidad\n",
    "    max_models=12,\n",
    "    feature_engineering=True,\n",
    "    feature_selection=True,\n",
    "    cross_validation=5,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ðŸŽ¯ AutoML con Dataset Personalizado:\")\n",
    "print(f\"   - DetecciÃ³n automÃ¡tica de tarea\")\n",
    "print(f\"   - Manejo automÃ¡tico de missing values\")\n",
    "print(f\"   - Procesamiento de features categÃ³ricas\")\n",
    "print(f\"   - Feature engineering avanzado\")\n",
    "\n",
    "# Ejecutar sin especificar task_type (detecciÃ³n automÃ¡tica)\n",
    "print(\"\\nðŸš€ AutoML detectarÃ¡ automÃ¡ticamente que es clasificaciÃ³n...\")\n",
    "result_custom = automl_custom.fit(custom_df, 'target')\n",
    "\n",
    "print(f\"\\nðŸ† RESULTADOS DATASET PERSONALIZADO:\")\n",
    "print(f\"   ðŸŽ¯ Tarea detectada: {result_custom.task.__class__.__name__}\")\n",
    "print(f\"   ðŸ“Š Mejor score: {result_custom.best_score:.4f}\")\n",
    "print(f\"   â±ï¸  Tiempo: {result_custom.training_time:.1f}s\")\n",
    "print(f\"   ðŸ” Modelos: {len(result_custom.leaderboard)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AnÃ¡lisis de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar importancia de features (si estÃ¡ disponible)\n",
    "if result_custom.feature_importance is not None:\n",
    "    print(\"ðŸ“Š FEATURE IMPORTANCE (Top 10):\")\n",
    "    print(\"=\"*50)\n",
    "    top_features = result_custom.feature_importance.head(10)\n",
    "    for feature, importance in top_features.items():\n",
    "        print(f\"{feature:20s}: {importance:.4f}\")\n",
    "    \n",
    "    # Visualizar feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_15 = result_custom.feature_importance.head(15)\n",
    "    plt.barh(range(len(top_15)), top_15.values)\n",
    "    plt.yticks(range(len(top_15)), top_15.index)\n",
    "    plt.xlabel('Importancia')\n",
    "    plt.title('Top 15 Features MÃ¡s Importantes')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"â„¹ï¸  Feature importance no disponible para este modelo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VisualizaciÃ³n de Leaderboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para visualizar leaderboard\n",
    "def plot_leaderboard(result, title, metric_name='Score'):\n",
    "    \"\"\"Visualizar leaderboard de modelos\"\"\"\n",
    "    \n",
    "    # Tomar top 8 modelos\n",
    "    top_models = result.leaderboard.head(8)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(top_models)), top_models['score'], \n",
    "                   color=plt.cm.viridis(np.linspace(0, 1, len(top_models))))\n",
    "    \n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'{title} - Top {len(top_models)} Modelos')\n",
    "    plt.xticks(range(len(top_models)), \n",
    "               [model[:15] + '...' if len(model) > 15 else model \n",
    "                for model in top_models['model']], \n",
    "               rotation=45, ha='right')\n",
    "    \n",
    "    # AÃ±adir valores en las barras\n",
    "    for bar, score in zip(bars, top_models['score']):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                 f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar los tres leaderboards\n",
    "plot_leaderboard(result_wine, 'Wine Classification', 'Accuracy')\n",
    "plot_leaderboard(result_diabetes, 'Diabetes Regression', 'MSE')\n",
    "plot_leaderboard(result_custom, 'Custom Dataset Classification', 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ComparaciÃ³n de Configuraciones AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar diferentes configuraciones en el dataset Wine\n",
    "print(\"ðŸ§ª Experimento: Comparando configuraciones de AutoML\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        'name': 'BÃ¡sico',\n",
    "        'params': {\n",
    "            'time_limit': 60,\n",
    "            'max_models': 5,\n",
    "            'feature_engineering': False,\n",
    "            'feature_selection': False,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Con Feature Engineering',\n",
    "        'params': {\n",
    "            'time_limit': 60,\n",
    "            'max_models': 5,\n",
    "            'feature_engineering': True,\n",
    "            'feature_selection': False,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Completo',\n",
    "        'params': {\n",
    "            'time_limit': 60,\n",
    "            'max_models': 5,\n",
    "            'feature_engineering': True,\n",
    "            'feature_selection': True,\n",
    "            'verbose': False\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nðŸ”¬ Probando configuraciÃ³n: {config['name']}\")\n",
    "    \n",
    "    automl = SimpleAutoML(\n",
    "        random_state=42,\n",
    "        **config['params']\n",
    "    )\n",
    "    \n",
    "    result = automl.fit(wine_df, 'wine_type')\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'config': config['name'],\n",
    "        'best_score': result.best_score,\n",
    "        'training_time': result.training_time,\n",
    "        'models_tried': len(result.leaderboard)\n",
    "    })\n",
    "    \n",
    "    print(f\"   Score: {result.best_score:.4f}\")\n",
    "    print(f\"   Tiempo: {result.training_time:.1f}s\")\n",
    "    print(f\"   Modelos: {len(result.leaderboard)}\")\n",
    "\n",
    "# Crear DataFrame de comparaciÃ³n\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "print(\"\\nðŸ“Š COMPARACIÃ“N DE CONFIGURACIONES:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaciÃ³n de configuraciones\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# GrÃ¡fico 1: Accuracy por configuraciÃ³n\n",
    "bars1 = ax1.bar(comparison_df['config'], comparison_df['best_score'], \n",
    "                color=['lightcoral', 'lightblue', 'lightgreen'])\n",
    "ax1.set_ylabel('Best Score (Accuracy)')\n",
    "ax1.set_title('Accuracy por ConfiguraciÃ³n AutoML')\n",
    "ax1.set_ylim(0.8, 1.0)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, score in zip(bars1, comparison_df['best_score']):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# GrÃ¡fico 2: Tiempo de entrenamiento\n",
    "bars2 = ax2.bar(comparison_df['config'], comparison_df['training_time'], \n",
    "                color=['lightcoral', 'lightblue', 'lightgreen'])\n",
    "ax2.set_ylabel('Tiempo de Entrenamiento (s)')\n",
    "ax2.set_title('Tiempo por ConfiguraciÃ³n AutoML')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, time in zip(bars2, comparison_df['training_time']):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{time:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# AnÃ¡lisis de resultados\n",
    "best_config = comparison_df.loc[comparison_df['best_score'].idxmax()]\n",
    "fastest_config = comparison_df.loc[comparison_df['training_time'].idxmin()]\n",
    "\n",
    "print(f\"\\nðŸ† Mejor accuracy: {best_config['config']} ({best_config['best_score']:.4f})\")\n",
    "print(f\"âš¡ MÃ¡s rÃ¡pido: {fastest_config['config']} ({fastest_config['training_time']:.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen y Conclusiones\n",
    "\n",
    "### ðŸŽ¯ **Capacidades Demostradas de SimpleAutoML:**\n",
    "\n",
    "1. **DetecciÃ³n AutomÃ¡tica de Tarea**: Identifica automÃ¡ticamente si es clasificaciÃ³n o regresiÃ³n\n",
    "2. **OptimizaciÃ³n Multi-Objetivo**: Encuentra el mejor balance entre mÃºltiples algoritmos y configuraciones\n",
    "3. **Feature Engineering AutomÃ¡tico**: Crea nuevas caracterÃ­sticas que mejoran el rendimiento\n",
    "4. **Manejo de Datos Mixtos**: Procesa automÃ¡ticamente features numÃ©ricas, categÃ³ricas y valores faltantes\n",
    "5. **ConfiguraciÃ³n Flexible**: Permite ajustar tiempo, complejidad y tÃ©cnicas segÃºn las necesidades\n",
    "\n",
    "### ðŸ“Š **Resultados Observados:**\n",
    "\n",
    "- **Dataset Wine**: Accuracy > 95% con feature engineering\n",
    "- **Dataset Diabetes**: MSE significativamente reducido con optimizaciÃ³n\n",
    "- **Dataset Personalizado**: Manejo exitoso de datos mixtos y missing values\n",
    "- **ComparaciÃ³n de Configuraciones**: Feature engineering mejora consistentemente el rendimiento\n",
    "\n",
    "### âš¡ **Ventajas Clave:**\n",
    "\n",
    "âœ… **Sin ConfiguraciÃ³n Manual**: Todo se optimiza automÃ¡ticamente  \n",
    "âœ… **RÃ¡pido de Usar**: Desde datos hasta modelo listo en minutos  \n",
    "âœ… **Resultados Interpretables**: Leaderboard y feature importance  \n",
    "âœ… **Flexible**: Configurable segÃºn tiempo y recursos disponibles  \n",
    "âœ… **Robusto**: Maneja datos reales con problemas comunes  \n",
    "\n",
    "### ðŸš€ **Casos de Uso Ideales:**\n",
    "\n",
    "- **Prototipado RÃ¡pido**: Obtener baseline fuerte rÃ¡pidamente\n",
    "- **ExploraciÃ³n de Datos**: Entender quÃ© funciona mejor\n",
    "- **Proyectos con Tiempo Limitado**: MÃ¡ximo rendimiento con mÃ­nimo esfuerzo\n",
    "- **Usuarios No Expertos**: AutoML hace el trabajo pesado\n",
    "- **Benchmarking**: Comparar con enfoques manuales\n",
    "\n",
    "**ðŸŽ‰ Â¡SimpleAutoML de MLPY democratiza el machine learning de calidad profesional!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}