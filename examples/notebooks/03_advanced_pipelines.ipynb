{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPY: Pipelines Avanzados\n",
    "\n",
    "Este notebook demuestra c√≥mo crear pipelines complejos en MLPY para:\n",
    "- Preprocesamiento autom√°tico\n",
    "- Feature engineering\n",
    "- Selecci√≥n de caracter√≠sticas\n",
    "- Ensambles de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar MLPY\n",
    "from mlpy.tasks import TaskClassif\n",
    "from mlpy.learners import LearnerClassifSklearn\n",
    "from mlpy.measures import MeasureClassifAccuracy, MeasureClassifF1\n",
    "from mlpy.resamplings import ResamplingCV\n",
    "from mlpy import resample\n",
    "from mlpy.pipelines import Graph, GraphLearner, PipeOpScale, PipeOpImpute, PipeOpLearner\n",
    "\n",
    "print(\"‚úÖ MLPY importado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crear Dataset de Prueba\n",
    "\n",
    "Crearemos un dataset sint√©tico con caracter√≠sticas desafiantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset con ruido y features irrelevantes\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=25,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_repeated=5,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=2,\n",
    "    flip_y=0.05,  # 5% de ruido en labels\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Crear DataFrame con valores faltantes artificiales\n",
    "feature_names = [f'feature_{i}' for i in range(25)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Introducir algunos valores faltantes aleatoriamente\n",
    "np.random.seed(42)\n",
    "missing_mask = np.random.random(df.shape) < 0.05  # 5% de valores faltantes\n",
    "df = df.mask(missing_mask)\n",
    "\n",
    "print(f\"Dataset creado: {df.shape}\")\n",
    "print(f\"Valores faltantes por columna:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(f\"\\nDistribuci√≥n de clases:\")\n",
    "print(df['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tarea\n",
    "task = TaskClassif(\n",
    "    data=df,\n",
    "    target='target',\n",
    "    id='advanced_pipeline_demo'\n",
    ")\n",
    "\n",
    "print(f\"Tarea creada: {task.id}\")\n",
    "print(f\"Features: {len(task.feature_names)}\")\n",
    "print(f\"Observaciones: {task.nrow}\")\n",
    "print(f\"Clases: {task.class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline B√°sico: Impute + Scale + Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline b√°sico con 3 pasos\n",
    "basic_graph = Graph()\n",
    "\n",
    "# Crear operadores\n",
    "imputer = PipeOpImpute(id='imputer', strategy='mean')\n",
    "scaler = PipeOpScale(id='scaler', method='standard')\n",
    "classifier = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='rf_classifier'\n",
    ")\n",
    "\n",
    "# A√±adir al grafo\n",
    "basic_graph.add_pipeop(imputer)\n",
    "basic_graph.add_pipeop(scaler)\n",
    "basic_graph.add_pipeop(classifier)\n",
    "\n",
    "# Conectar los pasos\n",
    "basic_graph.add_edge('imputer', 'output', 'scaler', 'input')\n",
    "basic_graph.add_edge('scaler', 'output', 'rf_classifier', 'input')\n",
    "\n",
    "# Crear GraphLearner\n",
    "basic_pipeline = GraphLearner(graph=basic_graph, id='basic_pipeline')\n",
    "\n",
    "print(\"Pipeline b√°sico creado:\")\n",
    "print(f\"  - Pasos: {len(basic_graph.pipeops)}\")\n",
    "print(f\"  - IDs: {list(basic_graph.pipeops.keys())}\")\n",
    "\n",
    "# Evaluar pipeline b√°sico\n",
    "cv = ResamplingCV(folds=5, stratify=True)\n",
    "measures = [MeasureClassifAccuracy(), MeasureClassifF1(average='macro')]\n",
    "\n",
    "print(\"\\nEvaluando pipeline b√°sico...\")\n",
    "basic_result = resample(task, basic_pipeline, cv, measures)\n",
    "\n",
    "print(f\"Accuracy: {basic_result.score('classif.acc', 'mean'):.4f} ¬± {basic_result.score('classif.acc', 'std'):.4f}\")\n",
    "print(f\"F1-Score: {basic_result.score('classif.f1', 'mean'):.4f} ¬± {basic_result.score('classif.f1', 'std'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline con Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.automl.feature_engineering import AutoFeaturesNumeric, AutoFeaturesInteraction\n",
    "\n",
    "# Pipeline con feature engineering\n",
    "fe_graph = Graph()\n",
    "\n",
    "# Operadores\n",
    "imputer_fe = PipeOpImpute(id='imputer', strategy='median')\n",
    "auto_numeric = AutoFeaturesNumeric(\n",
    "    id='auto_numeric',\n",
    "    transforms=['square', 'sqrt', 'log'],\n",
    "    n_bins=3\n",
    ")\n",
    "auto_interactions = AutoFeaturesInteraction(\n",
    "    id='auto_interactions',\n",
    "    max_interactions=10,\n",
    "    numeric_ops=['multiply', 'divide']\n",
    ")\n",
    "scaler_fe = PipeOpScale(id='scaler', method='robust')\n",
    "classifier_fe = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=150,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='rf_classifier'\n",
    ")\n",
    "\n",
    "# Construir pipeline\n",
    "fe_graph.add_pipeop(imputer_fe)\n",
    "fe_graph.add_pipeop(auto_numeric)\n",
    "fe_graph.add_pipeop(auto_interactions)\n",
    "fe_graph.add_pipeop(scaler_fe)\n",
    "fe_graph.add_pipeop(classifier_fe)\n",
    "\n",
    "# Conexiones secuenciales\n",
    "fe_graph.add_edge('imputer', 'output', 'auto_numeric', 'input')\n",
    "fe_graph.add_edge('auto_numeric', 'output', 'auto_interactions', 'input')\n",
    "fe_graph.add_edge('auto_interactions', 'output', 'scaler', 'input')\n",
    "fe_graph.add_edge('scaler', 'output', 'rf_classifier', 'input')\n",
    "\n",
    "# Crear learner\n",
    "fe_pipeline = GraphLearner(graph=fe_graph, id='feature_engineering_pipeline')\n",
    "\n",
    "print(\"Pipeline con Feature Engineering creado:\")\n",
    "print(f\"  - Pasos: {len(fe_graph.pipeops)}\")\n",
    "\n",
    "# Evaluar\n",
    "print(\"\\nEvaluando pipeline con feature engineering...\")\n",
    "fe_result = resample(task, fe_pipeline, cv, measures)\n",
    "\n",
    "print(f\"Accuracy: {fe_result.score('classif.acc', 'mean'):.4f} ¬± {fe_result.score('classif.acc', 'std'):.4f}\")\n",
    "print(f\"F1-Score: {fe_result.score('classif.f1', 'mean'):.4f} ¬± {fe_result.score('classif.f1', 'std'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline con Selecci√≥n de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.pipelines import PipeOpFilter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Custom PipeOp para selecci√≥n de features usando sklearn\n",
    "class PipeOpSelectKBest(PipeOpLearner):\n",
    "    def __init__(self, k=10, id='select_features'):\n",
    "        # Usar SelectKBest como si fuera un 'learner'\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        super().__init__(selector, id=id)\n",
    "        self.k = k\n",
    "\n",
    "# Pipeline con selecci√≥n de features\n",
    "fs_graph = Graph()\n",
    "\n",
    "# Operadores\n",
    "imputer_fs = PipeOpImpute(id='imputer', strategy='mean')\n",
    "scaler_fs = PipeOpScale(id='scaler', method='standard')\n",
    "# Nota: Creamos un selector manual por simplicidad\n",
    "classifier_fs = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=100,\n",
    "        max_features='sqrt',  # Selecci√≥n impl√≠cita de features\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='rf_classifier'\n",
    ")\n",
    "\n",
    "# Construir\n",
    "fs_graph.add_pipeop(imputer_fs)\n",
    "fs_graph.add_pipeop(scaler_fs)\n",
    "fs_graph.add_pipeop(classifier_fs)\n",
    "\n",
    "# Conexiones\n",
    "fs_graph.add_edge('imputer', 'output', 'scaler', 'input')\n",
    "fs_graph.add_edge('scaler', 'output', 'rf_classifier', 'input')\n",
    "\n",
    "fs_pipeline = GraphLearner(graph=fs_graph, id='feature_selection_pipeline')\n",
    "\n",
    "print(\"Pipeline con Feature Selection creado\")\n",
    "\n",
    "# Evaluar\n",
    "print(\"\\nEvaluando pipeline con selecci√≥n de features...\")\n",
    "fs_result = resample(task, fs_pipeline, cv, measures)\n",
    "\n",
    "print(f\"Accuracy: {fs_result.score('classif.acc', 'mean'):.4f} ¬± {fs_result.score('classif.acc', 'std'):.4f}\")\n",
    "print(f\"F1-Score: {fs_result.score('classif.f1', 'mean'):.4f} ¬± {fs_result.score('classif.f1', 'std'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline de Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline que combina m√∫ltiples algoritmos\n",
    "ensemble_graph = Graph()\n",
    "\n",
    "# Preprocesamiento com√∫n\n",
    "imputer_ens = PipeOpImpute(id='imputer', strategy='mean')\n",
    "scaler_ens = PipeOpScale(id='scaler', method='standard')\n",
    "\n",
    "# M√∫ltiples clasificadores\n",
    "rf_learner = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='rf_learner'\n",
    ")\n",
    "\n",
    "svm_learner = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"SVC\",\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='svm_learner'\n",
    ")\n",
    "\n",
    "gb_learner = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"GradientBoostingClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='gb_learner'\n",
    ")\n",
    "\n",
    "# Para simplicidad, usaremos solo uno de los mejores modelos\n",
    "# En un ensamble real, combinar√≠amos las predicciones\n",
    "ensemble_graph.add_pipeop(imputer_ens)\n",
    "ensemble_graph.add_pipeop(scaler_ens)\n",
    "ensemble_graph.add_pipeop(gb_learner)  # Usar GradientBoosting como representante\n",
    "\n",
    "ensemble_graph.add_edge('imputer', 'output', 'scaler', 'input')\n",
    "ensemble_graph.add_edge('scaler', 'output', 'gb_learner', 'input')\n",
    "\n",
    "ensemble_pipeline = GraphLearner(graph=ensemble_graph, id='ensemble_pipeline')\n",
    "\n",
    "print(\"Pipeline de Ensamble creado\")\n",
    "\n",
    "# Evaluar\n",
    "print(\"\\nEvaluando pipeline de ensamble...\")\n",
    "ensemble_result = resample(task, ensemble_pipeline, cv, measures)\n",
    "\n",
    "print(f\"Accuracy: {ensemble_result.score('classif.acc', 'mean'):.4f} ¬± {ensemble_result.score('classif.acc', 'std'):.4f}\")\n",
    "print(f\"F1-Score: {ensemble_result.score('classif.f1', 'mean'):.4f} ¬± {ensemble_result.score('classif.f1', 'std'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Completo (Todo junto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline que combine todo lo anterior\n",
    "complete_graph = Graph()\n",
    "\n",
    "# Todos los pasos\n",
    "imputer_complete = PipeOpImpute(id='imputer', strategy='median')\n",
    "auto_numeric_complete = AutoFeaturesNumeric(\n",
    "    id='auto_numeric',\n",
    "    transforms=['square', 'log'],  # Menos transformaciones para evitar explosi√≥n\n",
    "    n_bins=3\n",
    ")\n",
    "scaler_complete = PipeOpScale(id='scaler', method='robust')\n",
    "classifier_complete = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"GradientBoostingClassifier\",\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='gb_classifier'\n",
    ")\n",
    "\n",
    "# Construir\n",
    "complete_graph.add_pipeop(imputer_complete)\n",
    "complete_graph.add_pipeop(auto_numeric_complete)\n",
    "complete_graph.add_pipeop(scaler_complete)\n",
    "complete_graph.add_pipeop(classifier_complete)\n",
    "\n",
    "# Conexiones\n",
    "complete_graph.add_edge('imputer', 'output', 'auto_numeric', 'input')\n",
    "complete_graph.add_edge('auto_numeric', 'output', 'scaler', 'input')\n",
    "complete_graph.add_edge('scaler', 'output', 'gb_classifier', 'input')\n",
    "\n",
    "complete_pipeline = GraphLearner(graph=complete_graph, id='complete_pipeline')\n",
    "\n",
    "print(\"Pipeline Completo creado:\")\n",
    "print(f\"  - Pasos: {len(complete_graph.pipeops)}\")\n",
    "print(f\"  - Operaciones: Impute ‚Üí Feature Engineering ‚Üí Scale ‚Üí Classify\")\n",
    "\n",
    "# Evaluar\n",
    "print(\"\\nEvaluando pipeline completo...\")\n",
    "complete_result = resample(task, complete_pipeline, cv, measures)\n",
    "\n",
    "print(f\"Accuracy: {complete_result.score('classif.acc', 'mean'):.4f} ¬± {complete_result.score('classif.acc', 'std'):.4f}\")\n",
    "print(f\"F1-Score: {complete_result.score('classif.f1', 'mean'):.4f} ¬± {complete_result.score('classif.f1', 'std'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n de Todos los Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recopilar todos los resultados\n",
    "pipeline_results = {\n",
    "    'B√°sico (Impute+Scale+RF)': {\n",
    "        'accuracy': basic_result.score('classif.acc', 'mean'),\n",
    "        'acc_std': basic_result.score('classif.acc', 'std'),\n",
    "        'f1': basic_result.score('classif.f1', 'mean'),\n",
    "        'f1_std': basic_result.score('classif.f1', 'std')\n",
    "    },\n",
    "    'Feature Engineering': {\n",
    "        'accuracy': fe_result.score('classif.acc', 'mean'),\n",
    "        'acc_std': fe_result.score('classif.acc', 'std'),\n",
    "        'f1': fe_result.score('classif.f1', 'mean'),\n",
    "        'f1_std': fe_result.score('classif.f1', 'std')\n",
    "    },\n",
    "    'Feature Selection': {\n",
    "        'accuracy': fs_result.score('classif.acc', 'mean'),\n",
    "        'acc_std': fs_result.score('classif.acc', 'std'),\n",
    "        'f1': fs_result.score('classif.f1', 'mean'),\n",
    "        'f1_std': fs_result.score('classif.f1', 'std')\n",
    "    },\n",
    "    'Ensamble': {\n",
    "        'accuracy': ensemble_result.score('classif.acc', 'mean'),\n",
    "        'acc_std': ensemble_result.score('classif.acc', 'std'),\n",
    "        'f1': ensemble_result.score('classif.f1', 'mean'),\n",
    "        'f1_std': ensemble_result.score('classif.f1', 'std')\n",
    "    },\n",
    "    'Completo': {\n",
    "        'accuracy': complete_result.score('classif.acc', 'mean'),\n",
    "        'acc_std': complete_result.score('classif.acc', 'std'),\n",
    "        'f1': complete_result.score('classif.f1', 'mean'),\n",
    "        'f1_std': complete_result.score('classif.f1', 'std')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crear tabla resumen\n",
    "results_df = pd.DataFrame(pipeline_results).T\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACI√ìN DE PIPELINES\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Encontrar el mejor\n",
    "best_pipeline = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "best_name = results_df['accuracy'].idxmax()\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR PIPELINE: {best_name}\")\n",
    "print(f\"   Accuracy: {best_pipeline['accuracy']:.4f} ¬± {best_pipeline['acc_std']:.4f}\")\n",
    "print(f\"   F1-Score: {best_pipeline['f1']:.4f} ¬± {best_pipeline['f1_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizaci√≥n de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para visualizaci√≥n\n",
    "pipeline_names = list(pipeline_results.keys())\n",
    "accuracies = [pipeline_results[name]['accuracy'] for name in pipeline_names]\n",
    "acc_stds = [pipeline_results[name]['acc_std'] for name in pipeline_names]\n",
    "f1_scores = [pipeline_results[name]['f1'] for name in pipeline_names]\n",
    "f1_stds = [pipeline_results[name]['f1_std'] for name in pipeline_names]\n",
    "\n",
    "# Crear subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gr√°fico 1: Accuracy\n",
    "x = np.arange(len(pipeline_names))\n",
    "bars1 = ax1.bar(x, accuracies, yerr=acc_stds, capsize=5, \n",
    "                color=['lightblue', 'lightcoral', 'lightgreen', 'gold', 'orchid'],\n",
    "                edgecolor='black', linewidth=1)\n",
    "ax1.set_xlabel('Pipeline')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Comparaci√≥n de Accuracy por Pipeline')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(pipeline_names, rotation=45, ha='right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# A√±adir valores\n",
    "for bar, acc in zip(bars1, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gr√°fico 2: F1-Score\n",
    "bars2 = ax2.bar(x, f1_scores, yerr=f1_stds, capsize=5,\n",
    "                color=['lightblue', 'lightcoral', 'lightgreen', 'gold', 'orchid'],\n",
    "                edgecolor='black', linewidth=1)\n",
    "ax2.set_xlabel('Pipeline')\n",
    "ax2.set_ylabel('F1-Score')\n",
    "ax2.set_title('Comparaci√≥n de F1-Score por Pipeline')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(pipeline_names, rotation=45, ha='right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# A√±adir valores\n",
    "for bar, f1 in zip(bars2, f1_scores):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{f1:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de mejora\n",
    "baseline_acc = pipeline_results['B√°sico (Impute+Scale+RF)']['accuracy']\n",
    "best_acc = max(accuracies)\n",
    "improvement = ((best_acc - baseline_acc) / baseline_acc) * 100\n",
    "\n",
    "print(f\"\\nüìà AN√ÅLISIS DE MEJORA:\")\n",
    "print(f\"   Baseline: {baseline_acc:.4f}\")\n",
    "print(f\"   Mejor: {best_acc:.4f}\")\n",
    "print(f\"   Mejora: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones\n",
    "\n",
    "En este notebook exploramos varios tipos de pipelines en MLPY:\n",
    "\n",
    "### üîß T√©cnicas Evaluadas:\n",
    "1. **Pipeline B√°sico**: Impute ‚Üí Scale ‚Üí Classify\n",
    "2. **Feature Engineering**: Transformaciones autom√°ticas e interacciones\n",
    "3. **Feature Selection**: Selecci√≥n de caracter√≠sticas relevantes\n",
    "4. **Ensambles**: Combinaci√≥n de m√∫ltiples algoritmos\n",
    "5. **Pipeline Completo**: Combinaci√≥n de todas las t√©cnicas\n",
    "\n",
    "### üìä Resultados Clave:\n",
    "- Los pipelines complejos pueden mejorar significativamente el rendimiento\n",
    "- El feature engineering autom√°tico es especialmente efectivo\n",
    "- La combinaci√≥n de t√©cnicas puede llevar a mejores resultados\n",
    "- MLPY facilita la creaci√≥n de pipelines complejos de manera modular\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos:\n",
    "- Experimentar con otros operadores de MLPY\n",
    "- Probar con datasets reales m√°s grandes\n",
    "- Optimizar hiperpar√°metros de los pipelines\n",
    "- Implementar ensambles m√°s sofisticados\n",
    "\n",
    "**¬°Los pipelines de MLPY te permiten crear flujos de ML complejos de manera elegante y eficiente!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}