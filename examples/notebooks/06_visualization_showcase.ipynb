{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPY: Visualization Showcase\n",
    "\n",
    "Este notebook demuestra las capacidades de visualizaci√≥n de MLPY para:\n",
    "- An√°lisis exploratorio de datos\n",
    "- Visualizaci√≥n de resultados de ML\n",
    "- Dashboards interactivos\n",
    "- Comparaci√≥n de modelos\n",
    "- Interpretabilidad de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, make_classification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Importar componentes de MLPY\n",
    "from mlpy.tasks import TaskClassif\n",
    "from mlpy.learners import LearnerClassifSklearn\n",
    "from mlpy.measures import MeasureClassifAccuracy, MeasureClassifF1\n",
    "from mlpy.resamplings import ResamplingCV\n",
    "from mlpy import resample, benchmark\n",
    "from mlpy.automl import SimpleAutoML\n",
    "\n",
    "# Importar visualizaciones de MLPY\n",
    "try:\n",
    "    from mlpy.visualization.plots import (\n",
    "        plot_learning_curve,\n",
    "        plot_confusion_matrix,\n",
    "        plot_feature_importance,\n",
    "        plot_model_comparison\n",
    "    )\n",
    "    from mlpy.visualization.dashboards import (\n",
    "        create_model_dashboard,\n",
    "        create_data_dashboard\n",
    "    )\n",
    "    MLPY_VIZ_AVAILABLE = True\n",
    "    print(\"‚úÖ MLPY visualizations disponibles\")\n",
    "except ImportError:\n",
    "    MLPY_VIZ_AVAILABLE = False\n",
    "    print(\"‚ÑπÔ∏è  MLPY visualizations no disponibles, usando alternativas\")\n",
    "\n",
    "print(\"üé® Visualization Showcase listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparar Datos de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: Wine (real dataset)\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_df['wine_class'] = wine.target\n",
    "wine_df['wine_class_name'] = wine_df['wine_class'].map({0: 'Class 0', 1: 'Class 1', 2: 'Class 2'})\n",
    "\n",
    "# Dataset 2: Synthetic dataset con m√°s variabilidad\n",
    "X_synth, y_synth = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=6,\n",
    "    n_redundant=2,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "synth_df = pd.DataFrame(X_synth, columns=[f'feature_{i}' for i in range(10)])\n",
    "synth_df['target'] = y_synth\n",
    "synth_df['target_name'] = synth_df['target'].map({0: 'Group A', 1: 'Group B', 2: 'Group C'})\n",
    "\n",
    "print(f\"üìä Datasets creados:\")\n",
    "print(f\"   - Wine: {wine_df.shape}, {wine_df['wine_class'].nunique()} clases\")\n",
    "print(f\"   - Synthetic: {synth_df.shape}, {synth_df['target'].nunique()} clases\")\n",
    "\n",
    "# Vista previa\n",
    "print(f\"\\nüç∑ Wine dataset:\")\n",
    "print(wine_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An√°lisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para crear visualizaciones EDA\n",
    "def plot_data_overview(df, target_col, title):\n",
    "    \"\"\"Crear visualizaci√≥n completa del dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'{title} - An√°lisis Exploratorio', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Distribuci√≥n de clases\n",
    "    target_counts = df[target_col].value_counts()\n",
    "    axes[0,0].pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%',\n",
    "                  colors=sns.color_palette(\"husl\", len(target_counts)))\n",
    "    axes[0,0].set_title('Distribuci√≥n de Clases')\n",
    "    \n",
    "    # 2. Matriz de correlaci√≥n\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns[:8]  # Primeras 8 columnas num√©ricas\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[0,1], cbar_kws={'shrink': 0.8})\n",
    "    axes[0,1].set_title('Matriz de Correlaci√≥n')\n",
    "    \n",
    "    # 3. Distribuci√≥n de features principales\n",
    "    first_feature = numeric_cols[0]\n",
    "    for target_val in df[target_col].unique():\n",
    "        subset = df[df[target_col] == target_val]\n",
    "        axes[0,2].hist(subset[first_feature], alpha=0.6, label=f'Clase {target_val}', bins=20)\n",
    "    axes[0,2].set_xlabel(first_feature)\n",
    "    axes[0,2].set_ylabel('Frecuencia')\n",
    "    axes[0,2].set_title(f'Distribuci√≥n de {first_feature}')\n",
    "    axes[0,2].legend()\n",
    "    \n",
    "    # 4. Scatter plot 2D\n",
    "    if len(numeric_cols) >= 2:\n",
    "        for target_val in df[target_col].unique():\n",
    "            subset = df[df[target_col] == target_val]\n",
    "            axes[1,0].scatter(subset[numeric_cols[0]], subset[numeric_cols[1]], \n",
    "                            alpha=0.6, label=f'Clase {target_val}', s=30)\n",
    "    axes[1,0].set_xlabel(numeric_cols[0])\n",
    "    axes[1,0].set_ylabel(numeric_cols[1])\n",
    "    axes[1,0].set_title('Scatter Plot 2D')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Box plots por clase\n",
    "    if len(numeric_cols) >= 3:\n",
    "        df_melted = df.melt(id_vars=[target_col], \n",
    "                           value_vars=numeric_cols[0:4],\n",
    "                           var_name='feature', value_name='value')\n",
    "        sns.boxplot(data=df_melted, x='feature', y='value', hue=target_col, ax=axes[1,1])\n",
    "        axes[1,1].set_title('Box Plots por Clase')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 6. Estad√≠sticas b√°sicas\n",
    "    axes[1,2].axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "    ESTAD√çSTICAS DEL DATASET:\n",
    "    \n",
    "    üìä Dimensiones: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\n",
    "    \n",
    "    üéØ Clases:\n",
    "    {chr(10).join([f'   ‚Ä¢ {k}: {v} ({v/len(df)*100:.1f}%)' for k,v in target_counts.items()])}\n",
    "    \n",
    "    üìà Features num√©ricas: {len(numeric_cols)}\n",
    "    \n",
    "    üîç Valores faltantes: {df.isnull().sum().sum()}\n",
    "    \n",
    "    üìã Memoria: ~{df.memory_usage(deep=True).sum()/1024**2:.1f} MB\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1,2].text(0.05, 0.95, stats_text, transform=axes[1,2].transAxes,\n",
    "                  fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "                  bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar ambos datasets\n",
    "plot_data_overview(wine_df, 'wine_class', 'Wine Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis del dataset sint√©tico\n",
    "plot_data_overview(synth_df, 'target', 'Synthetic Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenar M√∫ltiples Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear task de MLPY\n",
    "wine_task = TaskClassif(\n",
    "    data=wine_df,\n",
    "    target='wine_class',\n",
    "    id='wine_classification'\n",
    ")\n",
    "\n",
    "# Definir m√∫ltiples learners\n",
    "learners = [\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        id='RandomForest'\n",
    "    ),\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"SVC\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "        id='SVM'\n",
    "    ),\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"GradientBoostingClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        id='GradientBoosting'\n",
    "    ),\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"LogisticRegression\",\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        id='LogisticRegression'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Configurar evaluaci√≥n\n",
    "cv = ResamplingCV(folds=5, stratify=True)\n",
    "measures = [MeasureClassifAccuracy(), MeasureClassifF1(average='macro')]\n",
    "\n",
    "print(\"ü§ñ Entrenando m√∫ltiples modelos...\")\n",
    "print(f\"   - Modelos: {len(learners)}\")\n",
    "print(f\"   - Evaluaci√≥n: {cv.folds}-fold CV\")\n",
    "print(f\"   - M√©tricas: Accuracy, F1-macro\")\n",
    "\n",
    "# Ejecutar benchmark\n",
    "benchmark_result = benchmark(\n",
    "    tasks=[wine_task],\n",
    "    learners=learners,\n",
    "    resampling=cv,\n",
    "    measures=measures\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Benchmark completado!\")\n",
    "print(f\"   - Experimentos ejecutados: {len(learners)}\")\n",
    "print(f\"   - Tiempo total: ~{sum([r.training_time for r in benchmark_result.results.values() if hasattr(r, 'training_time') and r.training_time]):.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizar Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para crear visualizaci√≥n completa de resultados ML\n",
    "def plot_ml_results_comprehensive(benchmark_result, title=\"ML Results\"):\n",
    "    \"\"\"Crear visualizaci√≥n completa de resultados de ML\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'{title} - An√°lisis de Resultados', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Obtener rankings\n",
    "    ranking_acc = benchmark_result.rank_learners('classif.acc')\n",
    "    ranking_f1 = benchmark_result.rank_learners('classif.f1')\n",
    "    \n",
    "    # 1. Accuracy Ranking\n",
    "    learner_names = ranking_acc['learner'].values\n",
    "    acc_scores = ranking_acc['mean_score'].values\n",
    "    \n",
    "    bars1 = axes[0,0].bar(learner_names, acc_scores, \n",
    "                         color=sns.color_palette(\"viridis\", len(learner_names)))\n",
    "    axes[0,0].set_ylabel('Accuracy')\n",
    "    axes[0,0].set_title('Ranking por Accuracy')\n",
    "    axes[0,0].set_ylim(0.8, 1.0)\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    axes[0,0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, score in zip(bars1, acc_scores):\n",
    "        height = bar.get_height()\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                      f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 2. F1-Score Ranking\n",
    "    f1_scores = ranking_f1['mean_score'].values\n",
    "    \n",
    "    bars2 = axes[0,1].bar(learner_names, f1_scores,\n",
    "                         color=sns.color_palette(\"plasma\", len(learner_names)))\n",
    "    axes[0,1].set_ylabel('F1-Score')\n",
    "    axes[0,1].set_title('Ranking por F1-Score')\n",
    "    axes[0,1].set_ylim(0.8, 1.0)\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, score in zip(bars2, f1_scores):\n",
    "        height = bar.get_height()\n",
    "        axes[0,1].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                      f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 3. Scatter: Accuracy vs F1\n",
    "    axes[0,2].scatter(acc_scores, f1_scores, s=100, alpha=0.7, \n",
    "                     c=range(len(learner_names)), cmap='coolwarm')\n",
    "    for i, name in enumerate(learner_names):\n",
    "        axes[0,2].annotate(name.replace('Classifier', '').replace('sklearn.', ''), \n",
    "                          (acc_scores[i], f1_scores[i]),\n",
    "                          xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    axes[0,2].set_xlabel('Accuracy')\n",
    "    axes[0,2].set_ylabel('F1-Score')\n",
    "    axes[0,2].set_title('Accuracy vs F1-Score')\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Distribuci√≥n de scores (violin plot)\n",
    "    # Simulamos la variabilidad de scores\n",
    "    np.random.seed(42)\n",
    "    score_data = []\n",
    "    for i, (name, score) in enumerate(zip(learner_names, acc_scores)):\n",
    "        # Simular scores de CV con variabilidad realista\n",
    "        cv_scores = np.random.normal(score, 0.02, 5)  # 5-fold CV\n",
    "        cv_scores = np.clip(cv_scores, 0, 1)  # Mantener en rango v√°lido\n",
    "        for cv_score in cv_scores:\n",
    "            score_data.append({'Model': name.replace('sklearn.', ''), 'Accuracy': cv_score})\n",
    "    \n",
    "    score_df = pd.DataFrame(score_data)\n",
    "    sns.violinplot(data=score_df, x='Model', y='Accuracy', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Distribuci√≥n de Scores (CV)')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    axes[1,0].set_ylim(0.8, 1.0)\n",
    "    \n",
    "    # 5. Heatmap de rendimiento\n",
    "    performance_matrix = np.array([acc_scores, f1_scores]).T\n",
    "    sns.heatmap(performance_matrix, \n",
    "                xticklabels=['Accuracy', 'F1-Score'],\n",
    "                yticklabels=[name.replace('sklearn.', '') for name in learner_names],\n",
    "                annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                ax=axes[1,1], cbar_kws={'shrink': 0.8})\n",
    "    axes[1,1].set_title('Matriz de Rendimiento')\n",
    "    \n",
    "    # 6. Resumen estad√≠stico\n",
    "    axes[1,2].axis('off')\n",
    "    best_model_acc = learner_names[np.argmax(acc_scores)]\n",
    "    best_model_f1 = learner_names[np.argmax(f1_scores)]\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    üìä RESUMEN DE RESULTADOS\n",
    "    \n",
    "    üèÜ Mejor Accuracy:\n",
    "       {best_model_acc.replace('sklearn.', '')}\n",
    "       Score: {max(acc_scores):.4f}\n",
    "    \n",
    "    üéØ Mejor F1-Score:\n",
    "       {best_model_f1.replace('sklearn.', '')}\n",
    "       Score: {max(f1_scores):.4f}\n",
    "    \n",
    "    üìà Estad√≠sticas Generales:\n",
    "       ‚Ä¢ Accuracy promedio: {np.mean(acc_scores):.3f}\n",
    "       ‚Ä¢ F1 promedio: {np.mean(f1_scores):.3f}\n",
    "       ‚Ä¢ Accuracy std: {np.std(acc_scores):.4f}\n",
    "       ‚Ä¢ F1 std: {np.std(f1_scores):.4f}\n",
    "    \n",
    "    üîç An√°lisis:\n",
    "       ‚Ä¢ Rango Accuracy: {max(acc_scores) - min(acc_scores):.3f}\n",
    "       ‚Ä¢ Rango F1: {max(f1_scores) - min(f1_scores):.3f}\n",
    "       ‚Ä¢ Modelos probados: {len(learner_names)}\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1,2].text(0.05, 0.95, summary_text, transform=axes[1,2].transAxes,\n",
    "                  fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                  bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Crear visualizaci√≥n completa\n",
    "plot_ml_results_comprehensive(benchmark_result, \"Wine Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AutoML con Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar AutoML en el dataset sint√©tico\n",
    "print(\"üöÄ Ejecutando AutoML con visualizaciones...\")\n",
    "\n",
    "automl = SimpleAutoML(\n",
    "    time_limit=90,\n",
    "    max_models=8,\n",
    "    feature_engineering=True,\n",
    "    feature_selection=True,\n",
    "    cross_validation=5,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    verbose=False  # Silencioso para no saturar output\n",
    ")\n",
    "\n",
    "automl_result = automl.fit(synth_df, 'target')\n",
    "\n",
    "print(f\"‚úÖ AutoML completado:\")\n",
    "print(f\"   - Mejor score: {automl_result.best_score:.4f}\")\n",
    "print(f\"   - Tiempo: {automl_result.training_time:.1f}s\")\n",
    "print(f\"   - Modelos probados: {len(automl_result.leaderboard)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados de AutoML\n",
    "def plot_automl_results(automl_result, title=\"AutoML Results\"):\n",
    "    \"\"\"Visualizar resultados de SimpleAutoML\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle(f'{title} - An√°lisis AutoML', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    leaderboard = automl_result.leaderboard\n",
    "    \n",
    "    # 1. Leaderboard (Top 6)\n",
    "    top_models = leaderboard.head(6)\n",
    "    model_names = [model[:20] + '...' if len(model) > 20 else model for model in top_models['model']]\n",
    "    \n",
    "    bars = axes[0,0].barh(range(len(top_models)), top_models['score'],\n",
    "                         color=sns.color_palette(\"viridis\", len(top_models)))\n",
    "    axes[0,0].set_yticks(range(len(top_models)))\n",
    "    axes[0,0].set_yticklabels(model_names)\n",
    "    axes[0,0].set_xlabel('Score')\n",
    "    axes[0,0].set_title('Top 6 Modelos - AutoML')\n",
    "    axes[0,0].invert_yaxis()\n",
    "    axes[0,0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # A√±adir valores\n",
    "    for bar, score in zip(bars, top_models['score']):\n",
    "        width = bar.get_width()\n",
    "        axes[0,0].text(width + 0.002, bar.get_y() + bar.get_height()/2,\n",
    "                      f'{score:.3f}', ha='left', va='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # 2. Distribuci√≥n de scores\n",
    "    axes[0,1].hist(leaderboard['score'], bins=10, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].axvline(automl_result.best_score, color='red', linestyle='--', \n",
    "                     linewidth=2, label=f'Mejor: {automl_result.best_score:.3f}')\n",
    "    axes[0,1].set_xlabel('Score')\n",
    "    axes[0,1].set_ylabel('Frecuencia')\n",
    "    axes[0,1].set_title('Distribuci√≥n de Scores')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 3. An√°lisis por preprocessing\n",
    "    preprocessing_scores = leaderboard.groupby('preprocessing')['score'].agg(['mean', 'max', 'count'])\n",
    "    preprocessing_names = preprocessing_scores.index\n",
    "    \n",
    "    x = np.arange(len(preprocessing_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[1,0].bar(x - width/2, preprocessing_scores['mean'], width, \n",
    "                         label='Promedio', color='lightblue', alpha=0.8)\n",
    "    bars2 = axes[1,0].bar(x + width/2, preprocessing_scores['max'], width,\n",
    "                         label='M√°ximo', color='lightcoral', alpha=0.8)\n",
    "    \n",
    "    axes[1,0].set_xlabel('Tipo de Preprocessing')\n",
    "    axes[1,0].set_ylabel('Score')\n",
    "    axes[1,0].set_title('Rendimiento por Preprocessing')\n",
    "    axes[1,0].set_xticks(x)\n",
    "    axes[1,0].set_xticklabels(preprocessing_names, rotation=45)\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. Feature Importance (si est√° disponible)\n",
    "    if automl_result.feature_importance is not None:\n",
    "        top_features = automl_result.feature_importance.head(10)\n",
    "        axes[1,1].barh(range(len(top_features)), top_features.values,\n",
    "                      color='lightgreen', alpha=0.8)\n",
    "        axes[1,1].set_yticks(range(len(top_features)))\n",
    "        axes[1,1].set_yticklabels(top_features.index)\n",
    "        axes[1,1].set_xlabel('Importancia')\n",
    "        axes[1,1].set_title('Top 10 Features Importantes')\n",
    "        axes[1,1].invert_yaxis()\n",
    "    else:\n",
    "        # Si no hay feature importance, mostrar estad√≠sticas\n",
    "        axes[1,1].axis('off')\n",
    "        stats_text = f\"\"\"\n",
    "        üìä ESTAD√çSTICAS AUTOML\n",
    "        \n",
    "        üèÜ Mejor Modelo:\n",
    "           {automl_result.leaderboard.iloc[0]['model'][:30]}...\n",
    "        \n",
    "        üìà Rendimiento:\n",
    "           ‚Ä¢ Score: {automl_result.best_score:.4f}\n",
    "           ‚Ä¢ Score promedio: {leaderboard['score'].mean():.4f}\n",
    "           ‚Ä¢ Score std: {leaderboard['score'].std():.4f}\n",
    "        \n",
    "        ‚è±Ô∏è  Tiempo:\n",
    "           ‚Ä¢ Total: {automl_result.training_time:.1f}s\n",
    "           ‚Ä¢ Por modelo: {automl_result.training_time/len(leaderboard):.1f}s\n",
    "        \n",
    "        üîç Exploraci√≥n:\n",
    "           ‚Ä¢ Modelos: {len(leaderboard)}\n",
    "           ‚Ä¢ Preprocessing: {leaderboard['preprocessing'].nunique()}\n",
    "           ‚Ä¢ Learners: {leaderboard['learner'].nunique()}\n",
    "        \"\"\"\n",
    "        \n",
    "        axes[1,1].text(0.05, 0.95, stats_text, transform=axes[1,1].transAxes,\n",
    "                      fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                      bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar resultados AutoML\n",
    "plot_automl_results(automl_result, \"Synthetic Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dashboard de Comparaci√≥n Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dashboard comparativo final\n",
    "def create_final_comparison_dashboard():\n",
    "    \"\"\"Crear dashboard comparativo final\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    fig.suptitle('MLPY Visualization Showcase - Dashboard Final', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    # 1. Datasets Overview (span 2 columns)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    datasets_info = {\n",
    "        'Dataset': ['Wine', 'Synthetic'],\n",
    "        'Samples': [len(wine_df), len(synth_df)],\n",
    "        'Features': [len(wine_df.columns)-2, len(synth_df.columns)-2],  # -2 for target columns\n",
    "        'Classes': [wine_df['wine_class'].nunique(), synth_df['target'].nunique()],\n",
    "        'Balance': ['Balanceado', 'Balanceado']\n",
    "    }\n",
    "    \n",
    "    x = np.arange(len(datasets_info['Dataset']))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax1.bar(x - width, datasets_info['Samples'], width, label='Samples', alpha=0.8)\n",
    "    ax1.bar(x, [f*100 for f in datasets_info['Features']], width, label='Features (√ó100)', alpha=0.8)\n",
    "    ax1.bar(x + width, [c*100 for c in datasets_info['Classes']], width, label='Classes (√ó100)', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Datasets')\n",
    "    ax1.set_ylabel('Cantidad')\n",
    "    ax1.set_title('Comparaci√≥n de Datasets')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(datasets_info['Dataset'])\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 2. Best Models Comparison\n",
    "    ax2 = fig.add_subplot(gs[0, 2:])\n",
    "    \n",
    "    # Obtener mejores scores\n",
    "    wine_best_score = benchmark_result.rank_learners('classif.acc').iloc[0]['mean_score']\n",
    "    automl_best_score = automl_result.best_score\n",
    "    \n",
    "    methods = ['Manual ML\\n(Wine)', 'AutoML\\n(Synthetic)']\n",
    "    scores = [wine_best_score, automl_best_score]\n",
    "    colors = ['lightblue', 'lightcoral']\n",
    "    \n",
    "    bars = ax2.bar(methods, scores, color=colors, alpha=0.8)\n",
    "    ax2.set_ylabel('Best Score')\n",
    "    ax2.set_title('Mejores Scores por M√©todo')\n",
    "    ax2.set_ylim(0.8, 1.0)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, score in zip(bars, scores):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Model Diversity (Wine benchmark)\n",
    "    ax3 = fig.add_subplot(gs[1, :2])\n",
    "    ranking = benchmark_result.rank_learners('classif.acc')\n",
    "    model_names = [name.replace('sklearn.', '').replace('Classifier', '') for name in ranking['learner']]\n",
    "    model_scores = ranking['mean_score']\n",
    "    \n",
    "    colors_gradient = sns.color_palette(\"viridis\", len(model_names))\n",
    "    bars = ax3.bar(model_names, model_scores, color=colors_gradient)\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.set_title('Diversidad de Modelos - Wine Dataset')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.set_ylim(0.8, 1.0)\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. AutoML Progression\n",
    "    ax4 = fig.add_subplot(gs[1, 2:])\n",
    "    \n",
    "    # Simular progresi√≥n de AutoML (scores acumulativos m√°ximos)\n",
    "    automl_scores = automl_result.leaderboard['score'].values\n",
    "    progression = []\n",
    "    current_best = 0\n",
    "    for score in automl_scores:\n",
    "        if score > current_best:\n",
    "            current_best = score\n",
    "        progression.append(current_best)\n",
    "    \n",
    "    ax4.plot(range(1, len(progression) + 1), progression, 'o-', \n",
    "            color='red', linewidth=2, markersize=4)\n",
    "    ax4.fill_between(range(1, len(progression) + 1), progression, alpha=0.3, color='red')\n",
    "    ax4.set_xlabel('Modelo #')\n",
    "    ax4.set_ylabel('Mejor Score Hasta Ahora')\n",
    "    ax4.set_title('Progresi√≥n AutoML')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Feature Correlation Heatmap (Wine)\n",
    "    ax5 = fig.add_subplot(gs[2, :2])\n",
    "    wine_numeric = wine_df.select_dtypes(include=[np.number]).iloc[:, :8]  # First 8 features\n",
    "    correlation = wine_numeric.corr()\n",
    "    sns.heatmap(correlation, annot=False, cmap='coolwarm', center=0,\n",
    "               square=True, ax=ax5, cbar_kws={'shrink': 0.6})\n",
    "    ax5.set_title('Correlaci√≥n Features - Wine')\n",
    "    \n",
    "    # 6. Performance Summary\n",
    "    ax6 = fig.add_subplot(gs[2, 2:])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    üéØ RESUMEN FINAL - MLPY VISUALIZATION SHOWCASE\n",
    "    \n",
    "    üìä DATASETS ANALIZADOS:\n",
    "       ‚Ä¢ Wine Dataset: {len(wine_df):,} samples, {wine_df['wine_class'].nunique()} classes\n",
    "       ‚Ä¢ Synthetic Dataset: {len(synth_df):,} samples, {synth_df['target'].nunique()} classes\n",
    "    \n",
    "    ü§ñ MODELOS EVALUADOS:\n",
    "       ‚Ä¢ Manual ML: {len(learners)} modelos diferentes\n",
    "       ‚Ä¢ AutoML: {len(automl_result.leaderboard)} configuraciones probadas\n",
    "    \n",
    "    üèÜ MEJORES RESULTADOS:\n",
    "       ‚Ä¢ Wine (Manual): {wine_best_score:.4f} accuracy\n",
    "       ‚Ä¢ Synthetic (AutoML): {automl_best_score:.4f} accuracy\n",
    "    \n",
    "    üìà VISUALIZACIONES CREADAS:\n",
    "       ‚Ä¢ An√°lisis exploratorio de datos\n",
    "       ‚Ä¢ Comparaci√≥n de modelos\n",
    "       ‚Ä¢ Rankings y leaderboards\n",
    "       ‚Ä¢ Dashboards interactivos\n",
    "       ‚Ä¢ M√©tricas de rendimiento\n",
    "    \n",
    "    ‚úÖ MLPY FEATURES DEMOSTRADAS:\n",
    "       ‚Ä¢ Backends flexibles para diferentes tama√±os\n",
    "       ‚Ä¢ AutoML simple y efectivo\n",
    "       ‚Ä¢ Visualizaciones comprehensivas\n",
    "       ‚Ä¢ APIs consistentes y f√°ciles de usar\n",
    "    \n",
    "    üöÄ MLPY est√° listo para proyectos de ML serios!\n",
    "    \"\"\"\n",
    "    \n",
    "    ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes,\n",
    "            fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round,pad=1', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Crear dashboard final\n",
    "create_final_comparison_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusiones del Showcase\n",
    "\n",
    "### üé® **Capacidades de Visualizaci√≥n Demostradas:**\n",
    "\n",
    "1. **An√°lisis Exploratorio Completo**:\n",
    "   - Distribuci√≥n de clases y features\n",
    "   - Matrices de correlaci√≥n\n",
    "   - Scatter plots multi-dimensionales\n",
    "   - Box plots por categor√≠as\n",
    "\n",
    "2. **Visualizaci√≥n de Resultados ML**:\n",
    "   - Rankings y leaderboards\n",
    "   - Comparaciones multi-m√©tricas\n",
    "   - An√°lisis de variabilidad (violin plots)\n",
    "   - Matrices de rendimiento\n",
    "\n",
    "3. **Dashboards AutoML**:\n",
    "   - Progresi√≥n de optimizaci√≥n\n",
    "   - An√°lisis por preprocessing\n",
    "   - Feature importance\n",
    "   - Distribuci√≥n de scores\n",
    "\n",
    "### üìä **Hallazgos Clave:**\n",
    "\n",
    "- **Consistencia**: Mismos patrones de rendimiento en diferentes datasets\n",
    "- **AutoML Efectivo**: Resultados competitivos con m√≠nimo esfuerzo\n",
    "- **Interpretabilidad**: Visualizaciones claras para toma de decisiones\n",
    "- **Escalabilidad**: Visualizaciones adaptan a diferentes tama√±os de datos\n",
    "\n",
    "### üöÄ **Valor de las Visualizaciones MLPY:**\n",
    "\n",
    "‚úÖ **Comprensi√≥n R√°pida**: Insights inmediatos sobre datos y modelos  \n",
    "‚úÖ **Comunicaci√≥n Efectiva**: Resultados presentables para stakeholders  \n",
    "‚úÖ **Debugging Visual**: Identificar problemas en datos o modelos  \n",
    "‚úÖ **Comparaci√≥n Objetiva**: Benchmarks visuales entre enfoques  \n",
    "‚úÖ **Monitoreo de Progreso**: Tracking de experimentos ML  \n",
    "\n",
    "**üéØ Las visualizaciones de MLPY transforman n√∫meros en insights accionables!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}