{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPY: Getting Started (Actualizado 2025)\n",
    "\n",
    "Este notebook te introducir√° a los conceptos b√°sicos de MLPY, un framework moderno de machine learning para Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n y Setup\n",
    "\n",
    "Primero, aseg√∫rate de tener MLPY instalado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no est√° instalado, descomenta la siguiente l√≠nea:\n",
    "# !pip install mlpy\n",
    "\n",
    "import mlpy\n",
    "print(f\"MLPY version: {mlpy.__version__}\")\n",
    "print(f\"MLPY est√° 100% funcional desde agosto 2025\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conceptos B√°sicos\n",
    "\n",
    "MLPY est√° construido alrededor de varios conceptos clave:\n",
    "\n",
    "- **Task**: Encapsula los datos y metadatos de un problema de ML\n",
    "- **Learner**: Interfaz unificada para algoritmos de ML\n",
    "- **Measure**: M√©tricas para evaluar el rendimiento\n",
    "- **Resampling**: Estrategias para evaluaci√≥n robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Importar componentes principales de MLPY\n",
    "from mlpy.tasks import TaskClassif\n",
    "from mlpy.learners import LearnerClassifSklearn\n",
    "from mlpy.measures import MeasureClassifAccuracy, MeasureClassifF1\n",
    "from mlpy.resamplings import ResamplingCV\n",
    "from mlpy import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crear una Tarea (Task)\n",
    "\n",
    "Vamos a trabajar con el dataset Iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target_names[iris.target]\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una tarea de clasificaci√≥n\n",
    "task = TaskClassif(\n",
    "    data=df,\n",
    "    target='species',\n",
    "    id='iris_classification'\n",
    ")\n",
    "\n",
    "# Explorar la tarea\n",
    "print(f\"Tipo de tarea: {task.task_type}\")\n",
    "print(f\"N√∫mero de features: {len(task.feature_names)}\")\n",
    "print(f\"N√∫mero de observaciones: {task.nrow}\")\n",
    "print(f\"Clases: {task.class_names}\")\n",
    "print(f\"N√∫mero de clases: {task.n_classes}\")\n",
    "print(f\"\\nFeatures disponibles:\")\n",
    "print(task.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crear un Learner\n",
    "\n",
    "Utilizaremos learners de scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear un Random Forest learner\n",
    "rf_learner = LearnerClassifSklearn(\n",
    "    classifier=\"RandomForestClassifier\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    id='random_forest'\n",
    ")\n",
    "\n",
    "print(f\"Learner ID: {rf_learner.id}\")\n",
    "print(f\"¬øEst√° entrenado?: {rf_learner.is_trained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenar y Predecir\n",
    "\n",
    "Veamos c√≥mo entrenar el modelo y hacer predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el learner\n",
    "rf_learner.train(task)\n",
    "print(f\"¬øEst√° entrenado ahora?: {rf_learner.is_trained}\")\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = rf_learner.predict(task)\n",
    "\n",
    "# Ver algunas predicciones\n",
    "print(\"\\nPrimeras 10 predicciones:\")\n",
    "print(predictions.response[:10])\n",
    "print(\"\\nClases reales:\")\n",
    "print(predictions.truth[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluar el Rendimiento\n",
    "\n",
    "Usemos medidas para evaluar las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear medidas\n",
    "accuracy = MeasureClassifAccuracy()\n",
    "f1 = MeasureClassifF1(average='macro')\n",
    "\n",
    "# Calcular scores\n",
    "acc_score = accuracy.score(predictions, task)\n",
    "f1_score = f1.score(predictions, task)\n",
    "\n",
    "print(f\"Accuracy: {acc_score:.3f}\")\n",
    "print(f\"F1-Score (macro): {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation\n",
    "\n",
    "Para una evaluaci√≥n m√°s robusta, usemos cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir estrategia de resampling\n",
    "cv = ResamplingCV(\n",
    "    folds=5,\n",
    "    stratify=True  # Mantener proporci√≥n de clases\n",
    ")\n",
    "\n",
    "# Ejecutar evaluaci√≥n con cross-validation\n",
    "result = resample(\n",
    "    task=task,\n",
    "    learner=rf_learner,\n",
    "    resampling=cv,\n",
    "    measures=[accuracy, f1]\n",
    ")\n",
    "\n",
    "print(f\"N√∫mero de iteraciones: {result.n_iters}\")\n",
    "print(f\"N√∫mero de errores: {result.n_errors}\")\n",
    "\n",
    "# Ver resultados agregados\n",
    "print(\"\\nResultados agregados:\")\n",
    "print(result.aggregate())\n",
    "\n",
    "# Obtener score promedio para accuracy\n",
    "print(f\"\\nAccuracy promedio: {result.score('classif.acc', 'mean'):.4f}\")\n",
    "print(f\"F1 promedio: {result.score('classif.f1', 'mean'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparar M√∫ltiples Modelos\n",
    "\n",
    "Creemos varios learners y comparemos su rendimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Lista de learners a comparar\n",
    "learners = [\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        id='random_forest'\n",
    "    ),\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"DecisionTreeClassifier\",\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        id='decision_tree'\n",
    "    ),\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"SVC\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "        id='svm'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Evaluar todos los learners\n",
    "results = {}\n",
    "for learner in learners:\n",
    "    print(f\"Evaluando {learner.id}...\")\n",
    "    result = resample(\n",
    "        task=task,\n",
    "        learner=learner,\n",
    "        resampling=cv,\n",
    "        measures=[accuracy]\n",
    "    )\n",
    "    results[learner.id] = result.score('classif.acc', 'mean')\n",
    "    print(f\"  Accuracy: {results[learner.id]:.4f}\")\n",
    "\n",
    "# Mostrar ranking\n",
    "print(\"\\nRanking de modelos:\")\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (name, score) in enumerate(sorted_results, 1):\n",
    "    print(f\"{i}. {name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Usar SimpleAutoML\n",
    "\n",
    "MLPY incluye una interfaz de AutoML simplificada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.automl import SimpleAutoML\n",
    "\n",
    "# Crear AutoML con configuraci√≥n r√°pida\n",
    "automl = SimpleAutoML(\n",
    "    time_limit=60,  # 1 minuto\n",
    "    max_models=5,   # Solo 5 modelos para demostraci√≥n\n",
    "    feature_engineering=True,\n",
    "    feature_selection=True,\n",
    "    cross_validation=3,  # 3 folds para rapidez\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ejecutar AutoML\n",
    "automl_result = automl.fit(df, 'species')\n",
    "\n",
    "print(f\"\\nüéØ Mejor score encontrado: {automl_result.best_score:.4f}\")\n",
    "print(f\"‚è±Ô∏è Tiempo total: {automl_result.training_time:.1f}s\")\n",
    "print(f\"üîç Modelos probados: {len(automl_result.leaderboard)}\")\n",
    "\n",
    "# Ver leaderboard\n",
    "print(\"\\nüìä Top 3 modelos:\")\n",
    "print(automl_result.leaderboard.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Crear un Pipeline\n",
    "\n",
    "MLPY soporta pipelines para preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpy.pipelines import Graph, GraphLearner, PipeOpScale, PipeOpLearner\n",
    "\n",
    "# Crear pipeline: escalar ‚Üí clasificar\n",
    "pipeline_graph = Graph()\n",
    "\n",
    "# A√±adir operadores\n",
    "scaler = PipeOpScale(id='scaler', method='standard')\n",
    "classifier = PipeOpLearner(\n",
    "    LearnerClassifSklearn(\n",
    "        classifier=\"RandomForestClassifier\",\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "    id='classifier'\n",
    ")\n",
    "\n",
    "pipeline_graph.add_pipeop(scaler)\n",
    "pipeline_graph.add_pipeop(classifier)\n",
    "pipeline_graph.add_edge('scaler', 'output', 'classifier', 'input')\n",
    "\n",
    "# Convertir a GraphLearner\n",
    "pipeline = GraphLearner(graph=pipeline_graph, id='pipeline_rf')\n",
    "\n",
    "# Evaluar el pipeline\n",
    "pipeline_result = resample(\n",
    "    task=task,\n",
    "    learner=pipeline,\n",
    "    resampling=cv,\n",
    "    measures=[accuracy, f1]\n",
    ")\n",
    "\n",
    "print(\"Pipeline (Scale + RF) - Resultados:\")\n",
    "print(f\"Accuracy: {pipeline_result.score('classif.acc', 'mean'):.4f}\")\n",
    "print(f\"F1-Score: {pipeline_result.score('classif.f1', 'mean'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizaci√≥n de Resultados\n",
    "\n",
    "Visualicemos la comparaci√≥n de modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preparar datos para visualizaci√≥n\n",
    "model_names = ['Random Forest', 'Decision Tree', 'SVM', 'AutoML', 'Pipeline']\n",
    "accuracies = [\n",
    "    results['random_forest'],\n",
    "    results['decision_tree'],\n",
    "    results['svm'],\n",
    "    automl_result.best_score,\n",
    "    pipeline_result.score('classif.acc', 'mean')\n",
    "]\n",
    "\n",
    "# Crear gr√°fico de barras\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(model_names, accuracies, \n",
    "               color=['lightblue', 'lightcoral', 'lightgreen', 'gold', 'orchid'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparaci√≥n de Modelos en Dataset Iris')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar el mejor modelo\n",
    "best_idx = accuracies.index(max(accuracies))\n",
    "print(f\"\\nüèÜ Mejor modelo: {model_names[best_idx]} con accuracy de {max(accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Pr√≥ximos Pasos\n",
    "\n",
    "¬°Felicidades! Has aprendido los conceptos b√°sicos de MLPY:\n",
    "\n",
    "1. ‚úÖ Crear tareas (Tasks)\n",
    "2. ‚úÖ Usar learners de scikit-learn\n",
    "3. ‚úÖ Evaluar modelos con measures\n",
    "4. ‚úÖ Usar cross-validation\n",
    "5. ‚úÖ Comparar m√∫ltiples modelos\n",
    "6. ‚úÖ Usar SimpleAutoML\n",
    "7. ‚úÖ Crear pipelines\n",
    "\n",
    "### Para explorar m√°s:\n",
    "\n",
    "- **Notebooks avanzados**: Consulta otros notebooks para ejemplos m√°s complejos\n",
    "- **Documentaci√≥n**: Lee la documentaci√≥n completa en el README\n",
    "- **Datasets grandes**: Prueba con backends Dask o Vaex\n",
    "- **Tuning avanzado**: Optimizaci√≥n de hiperpar√°metros con Optuna\n",
    "- **Visualizaci√≥n**: M√°s tipos de gr√°ficos para an√°lisis\n",
    "\n",
    "¬°MLPY est√° listo para proyectos de machine learning serios!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}