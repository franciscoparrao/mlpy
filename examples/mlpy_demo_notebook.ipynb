{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ MLPY Framework - DemostraciÃ³n Completa\n",
    "\n",
    "## California Housing Price Prediction\n",
    "\n",
    "Este notebook demuestra las capacidades completas del framework MLPY a travÃ©s de un problema real: la predicciÃ³n de precios de viviendas en California.\n",
    "\n",
    "### ğŸ“‹ Contenido\n",
    "\n",
    "1. **Carga y ValidaciÃ³n de Datos**\n",
    "2. **CreaciÃ³n de Tareas**\n",
    "3. **Modelos Base**\n",
    "4. **Modelos Avanzados**\n",
    "5. **Ensemble Learning**\n",
    "6. **Cross-Validation**\n",
    "7. **Model Registry**\n",
    "8. **ComparaciÃ³n con scikit-learn**\n",
    "9. **Visualizaciones**\n",
    "10. **Conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n inicial\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LibrerÃ­as estÃ¡ndar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… LibrerÃ­as base cargadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPY imports\n",
    "from mlpy.tasks import TaskRegr\n",
    "from mlpy.learners.baseline import LearnerRegrFeatureless\n",
    "from mlpy.learners.sklearn import (\n",
    "    LearnerLinearRegression,\n",
    "    LearnerRandomForestRegressor,\n",
    "    LearnerGradientBoostingRegressor\n",
    ")\n",
    "from mlpy.learners.ensemble import LearnerVoting\n",
    "from mlpy.resamplings import ResamplingCV, ResamplingHoldout\n",
    "from mlpy.measures import MeasureRegrMSE, MeasureRegrMAE\n",
    "from mlpy.validation.validators import validate_task_data\n",
    "from mlpy.model_registry.registry import ModelRegistry, ModelMetadata\n",
    "from mlpy.model_registry.registry import ModelCategory, TaskType, Complexity\n",
    "\n",
    "print(\"âœ… MLPY framework cargado\")\n",
    "print(f\"ğŸ“ VersiÃ³n: 2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Carga y ExploraciÃ³n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de California Housing\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "print(\"ğŸ“Š Cargando California Housing Dataset...\")\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "data = housing.frame\n",
    "\n",
    "# InformaciÃ³n bÃ¡sica\n",
    "display(Markdown(\"### ğŸ“ˆ InformaciÃ³n del Dataset\"))\n",
    "print(f\"â€¢ Forma: {data.shape}\")\n",
    "print(f\"â€¢ CaracterÃ­sticas: {list(housing.feature_names)}\")\n",
    "print(f\"â€¢ Variable objetivo: MedHouseVal (Valor medio de vivienda en $100,000s)\")\n",
    "print(f\"â€¢ Registros: {len(data):,}\")\n",
    "print(f\"â€¢ Sin valores faltantes: {data.isnull().sum().sum() == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista previa de los datos\n",
    "display(Markdown(\"### ğŸ” Primeras 5 filas\"))\n",
    "display(data.head())\n",
    "\n",
    "display(Markdown(\"### ğŸ“Š EstadÃ­sticas descriptivas\"))\n",
    "display(data.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n de distribuciones\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "fig.suptitle('DistribuciÃ³n de Variables', fontsize=16, y=1.02)\n",
    "\n",
    "for idx, col in enumerate(data.columns):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    data[col].hist(bins=30, ax=ax, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Valor')\n",
    "    ax.set_ylabel('Frecuencia')\n",
    "    \n",
    "    # AÃ±adir estadÃ­sticas\n",
    "    mean_val = data[col].mean()\n",
    "    median_val = data[col].median()\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', alpha=0.5, label=f'Media: {mean_val:.2f}')\n",
    "    ax.axvline(median_val, color='green', linestyle='--', alpha=0.5, label=f'Mediana: {median_val:.2f}')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ ValidaciÃ³n de Datos con MLPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el sistema de validaciÃ³n de MLPY\n",
    "display(Markdown(\"### ğŸ” ValidaciÃ³n AutomÃ¡tica de Datos\"))\n",
    "\n",
    "validation_result = validate_task_data(\n",
    "    data, \n",
    "    target='MedHouseVal',\n",
    "    task_type='regression'\n",
    ")\n",
    "\n",
    "# Mostrar resultados de validaciÃ³n\n",
    "status_emoji = \"âœ…\" if validation_result['valid'] else \"âŒ\"\n",
    "print(f\"\\n{status_emoji} Estado de ValidaciÃ³n: {'APROBADO' if validation_result['valid'] else 'FALLIDO'}\")\n",
    "print(f\"ğŸ“Š NÃºmero de muestras: {validation_result['stats']['n_samples']:,}\")\n",
    "print(f\"ğŸ”¢ NÃºmero de caracterÃ­sticas: {validation_result['stats']['n_features']}\")\n",
    "\n",
    "if validation_result.get('warnings'):\n",
    "    display(Markdown(\"### âš ï¸ Advertencias\"))\n",
    "    for warning in validation_result['warnings']:\n",
    "        print(f\"  â€¢ {warning}\")\n",
    "\n",
    "if validation_result.get('suggestions'):\n",
    "    display(Markdown(\"### ğŸ’¡ Sugerencias\"))\n",
    "    for suggestion in validation_result['suggestions']:\n",
    "        print(f\"  â€¢ {suggestion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ CreaciÃ³n de Tarea MLPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tarea de regresiÃ³n\n",
    "display(Markdown(\"### ğŸ¯ CreaciÃ³n de Tarea de RegresiÃ³n\"))\n",
    "\n",
    "task = TaskRegr(data=data, target='MedHouseVal')\n",
    "\n",
    "print(f\"âœ… Tarea creada: {task}\")\n",
    "print(f\"ğŸ“‹ Tipo de tarea: {task.task_type}\")\n",
    "print(f\"ğŸ“Š Observaciones: {task.nrow:,}\")\n",
    "print(f\"ğŸ”¢ CaracterÃ­sticas: {task.ncol - 1}\")\n",
    "print(f\"ğŸ“ Nombres de caracterÃ­sticas: {task.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear divisiÃ³n train/test\n",
    "display(Markdown(\"### ğŸ”€ DivisiÃ³n Train/Test (80/20)\"))\n",
    "\n",
    "holdout = ResamplingHoldout(ratio=0.2, stratify=False)\n",
    "holdout_instance = holdout.instantiate(task)\n",
    "\n",
    "train_idx = holdout_instance.train_set(0)\n",
    "test_idx = holdout_instance.test_set(0)\n",
    "\n",
    "train_task = task.filter(train_idx)\n",
    "test_task = task.filter(test_idx)\n",
    "\n",
    "# Mostrar informaciÃ³n de la divisiÃ³n\n",
    "train_size = len(train_idx)\n",
    "test_size = len(test_idx)\n",
    "total = train_size + test_size\n",
    "\n",
    "print(f\"ğŸ“š Conjunto de entrenamiento: {train_size:,} ({train_size/total*100:.1f}%)\")\n",
    "print(f\"ğŸ§ª Conjunto de prueba: {test_size:,} ({test_size/total*100:.1f}%)\")\n",
    "print(f\"ğŸ“Š Total: {total:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Modelo Base (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### ğŸ“ Entrenamiento del Modelo Baseline\"))\n",
    "print(\"El modelo baseline predice siempre la media del conjunto de entrenamiento.\\n\")\n",
    "\n",
    "# Entrenar modelo baseline\n",
    "baseline = LearnerRegrFeatureless(id=\"baseline\")\n",
    "\n",
    "start_time = time()\n",
    "baseline.train(train_task)\n",
    "baseline_train_time = time() - start_time\n",
    "\n",
    "# Predicciones\n",
    "baseline_pred = baseline.predict(test_task)\n",
    "\n",
    "# EvaluaciÃ³n\n",
    "mse_measure = MeasureRegrMSE()\n",
    "mae_measure = MeasureRegrMAE()\n",
    "\n",
    "baseline_mse = mse_measure.score(baseline_pred.truth, baseline_pred.response)\n",
    "baseline_mae = mae_measure.score(baseline_pred.truth, baseline_pred.response)\n",
    "\n",
    "# Mostrar resultados\n",
    "results_html = f\"\"\"\n",
    "<div style=\"background-color: #f0f0f0; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n",
    "    <h4>ğŸ“Š Resultados del Modelo Baseline</h4>\n",
    "    <ul style=\"list-style-type: none;\">\n",
    "        <li>ğŸ“‰ <b>MSE:</b> {baseline_mse:.4f}</li>\n",
    "        <li>ğŸ“ˆ <b>MAE:</b> {baseline_mae:.4f}</li>\n",
    "        <li>â±ï¸ <b>Tiempo de entrenamiento:</b> {baseline_train_time:.3f}s</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(results_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Modelos Avanzados con MLPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### ğŸš€ Entrenamiento de Modelos Avanzados\"))\n",
    "\n",
    "# Definir modelos a probar\n",
    "models = {\n",
    "    'Linear Regression': LearnerLinearRegression(),\n",
    "    'Random Forest': LearnerRandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': LearnerGradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for name, learner in models.items():\n",
    "    print(f\"\\nğŸ”„ Entrenando {name}...\")\n",
    "    \n",
    "    # Entrenar\n",
    "    start_time = time()\n",
    "    learner.train(train_task)\n",
    "    train_time = time() - start_time\n",
    "    \n",
    "    # Predecir\n",
    "    predictions = learner.predict(test_task)\n",
    "    \n",
    "    # Evaluar\n",
    "    mse = mse_measure.score(predictions.truth, predictions.response)\n",
    "    mae = mae_measure.score(predictions.truth, predictions.response)\n",
    "    \n",
    "    results[name] = {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'train_time': train_time,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    improvement = ((baseline_mse - mse) / baseline_mse) * 100\n",
    "    print(f\"  âœ… MSE: {mse:.4f} (mejora: {improvement:.1f}% vs baseline)\")\n",
    "    print(f\"  âœ… MAE: {mae:.4f}\")\n",
    "    print(f\"  â±ï¸ Tiempo: {train_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### ğŸ­ CreaciÃ³n de Ensemble con Voting\"))\n",
    "\n",
    "# Crear ensemble de votaciÃ³n\n",
    "base_learners = [\n",
    "    LearnerLinearRegression(id=\"lr\"),\n",
    "    LearnerRandomForestRegressor(n_estimators=50, random_state=42, id=\"rf\"),\n",
    "    LearnerGradientBoostingRegressor(n_estimators=50, random_state=42, id=\"gb\")\n",
    "]\n",
    "\n",
    "print(\"ğŸ“¦ Componentes del ensemble:\")\n",
    "print(\"  â€¢ Linear Regression (peso: 0.2)\")\n",
    "print(\"  â€¢ Random Forest (peso: 0.4)\")\n",
    "print(\"  â€¢ Gradient Boosting (peso: 0.4)\")\n",
    "\n",
    "voting_ensemble = LearnerVoting(\n",
    "    base_learners=base_learners,\n",
    "    voting='soft',\n",
    "    weights=[0.2, 0.4, 0.4]\n",
    ")\n",
    "\n",
    "# Entrenar ensemble\n",
    "print(\"\\nğŸ”„ Entrenando ensemble...\")\n",
    "start_time = time()\n",
    "voting_ensemble.train(train_task)\n",
    "ensemble_train_time = time() - start_time\n",
    "\n",
    "# Predecir\n",
    "ensemble_pred = voting_ensemble.predict(test_task)\n",
    "\n",
    "# Evaluar\n",
    "ensemble_mse = mse_measure.score(ensemble_pred.truth, ensemble_pred.response)\n",
    "ensemble_mae = mae_measure.score(ensemble_pred.truth, ensemble_pred.response)\n",
    "\n",
    "results['Voting Ensemble'] = {\n",
    "    'mse': ensemble_mse,\n",
    "    'mae': ensemble_mae,\n",
    "    'train_time': ensemble_train_time,\n",
    "    'predictions': ensemble_pred\n",
    "}\n",
    "\n",
    "# Mostrar resultados\n",
    "improvement = ((baseline_mse - ensemble_mse) / baseline_mse) * 100\n",
    "print(f\"\\nâœ… Ensemble MSE: {ensemble_mse:.4f} (mejora: {improvement:.1f}% vs baseline)\")\n",
    "print(f\"âœ… Ensemble MAE: {ensemble_mae:.4f}\")\n",
    "print(f\"â±ï¸ Tiempo de entrenamiento: {ensemble_train_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### ğŸ”„ 5-Fold Cross-Validation\"))\n",
    "\n",
    "# Encontrar el mejor modelo\n",
    "best_model_name = min(results.keys(), key=lambda x: results[x]['mse'])\n",
    "print(f\"ğŸ† Mejor modelo hasta ahora: {best_model_name}\")\n",
    "print(f\"   MSE: {results[best_model_name]['mse']:.4f}\")\n",
    "\n",
    "# Realizar cross-validation\n",
    "print(\"\\nğŸ”„ Ejecutando 5-fold cross-validation...\\n\")\n",
    "cv = ResamplingCV(folds=5)\n",
    "cv_instance = cv.instantiate(task)\n",
    "\n",
    "cv_scores = []\n",
    "for fold in range(5):\n",
    "    # Obtener datos del fold\n",
    "    train_idx = cv_instance.train_set(fold)\n",
    "    test_idx = cv_instance.test_set(fold)\n",
    "    \n",
    "    fold_train = task.filter(train_idx)\n",
    "    fold_test = task.filter(test_idx)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    if best_model_name == 'Random Forest':\n",
    "        model = LearnerRandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif best_model_name == 'Gradient Boosting':\n",
    "        model = LearnerGradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    elif best_model_name == 'Voting Ensemble':\n",
    "        model = voting_ensemble\n",
    "    else:\n",
    "        model = LearnerLinearRegression()\n",
    "    \n",
    "    model.train(fold_train)\n",
    "    \n",
    "    # Predecir y evaluar\n",
    "    pred = model.predict(fold_test)\n",
    "    fold_mse = mse_measure.score(pred.truth, pred.response)\n",
    "    cv_scores.append(fold_mse)\n",
    "    \n",
    "    print(f\"  Fold {fold+1}: MSE = {fold_mse:.4f}\")\n",
    "\n",
    "# Resultados de CV\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"background-color: #e8f5e9; padding: 15px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <h4>ğŸ“Š Resultados de Cross-Validation</h4>\n",
    "    <ul style=\"list-style-type: none;\">\n",
    "        <li>ğŸ“ˆ <b>MSE Promedio:</b> {cv_mean:.4f}</li>\n",
    "        <li>ğŸ“‰ <b>DesviaciÃ³n EstÃ¡ndar:</b> {cv_std:.4f}</li>\n",
    "        <li>ğŸ¯ <b>Intervalo de Confianza (95%):</b> [{cv_mean - 1.96*cv_std:.4f}, {cv_mean + 1.96*cv_std:.4f}]</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### ğŸ“š Registro del Mejor Modelo\"))\n",
    "\n",
    "# Inicializar registro\n",
    "registry = ModelRegistry()\n",
    "\n",
    "# Crear metadata del modelo\n",
    "metadata = ModelMetadata(\n",
    "    name=\"housing_price_predictor\",\n",
    "    display_name=\"California Housing Price Predictor\",\n",
    "    description=f\"Mejor modelo ({best_model_name}) para predicciÃ³n de precios de vivienda en California\",\n",
    "    category=ModelCategory.TRADITIONAL_ML,\n",
    "    class_path=f\"mlpy.learners.sklearn.Learner{best_model_name.replace(' ', '')}Regressor\",\n",
    "    task_types=[TaskType.REGRESSION],\n",
    "    complexity=Complexity.MEDIUM,\n",
    "    performance_metrics={\n",
    "        'mse': results[best_model_name]['mse'],\n",
    "        'mae': results[best_model_name]['mae'],\n",
    "        'cv_mse': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'train_time': results[best_model_name]['train_time']\n",
    "    },\n",
    "    tags=['housing', 'california', 'regression', 'production-ready'],\n",
    "    version='1.0.0'\n",
    ")\n",
    "\n",
    "# Registrar modelo\n",
    "registry.register(metadata)\n",
    "print(f\"âœ… Modelo registrado: {metadata.name}\")\n",
    "print(f\"ğŸ“‹ VersiÃ³n: {metadata.version}\")\n",
    "print(f\"ğŸ·ï¸ Tags: {', '.join(metadata.tags)}\")\n",
    "\n",
    "# Buscar en el registro\n",
    "print(\"\\nğŸ” BÃºsqueda en el registro...\")\n",
    "regression_models = registry.search(task_type=TaskType.REGRESSION)\n",
    "print(f\"ğŸ“Š Modelos de regresiÃ³n encontrados: {len(regression_models)}\")\n",
    "\n",
    "for model in regression_models:\n",
    "    print(f\"  â€¢ {model.display_name} (v{model.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ ComparaciÃ³n MLPY vs scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### âš”ï¸ MLPY vs scikit-learn\"))\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Preparar datos para sklearn\n",
    "X_train = train_task.data.drop('MedHouseVal', axis=1)\n",
    "y_train = train_task.data['MedHouseVal']\n",
    "X_test = test_task.data.drop('MedHouseVal', axis=1)\n",
    "y_test = test_task.data['MedHouseVal']\n",
    "\n",
    "# Entrenar modelo sklearn\n",
    "print(\"ğŸ”¬ Entrenando Random Forest con scikit-learn...\")\n",
    "sklearn_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "start_time = time()\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sklearn_train_time = time() - start_time\n",
    "\n",
    "sklearn_pred = sklearn_rf.predict(X_test)\n",
    "sklearn_mse = mean_squared_error(y_test, sklearn_pred)\n",
    "\n",
    "# Crear tabla de comparaciÃ³n\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Framework': ['MLPY', 'scikit-learn'],\n",
    "    'MSE': [results['Random Forest']['mse'], sklearn_mse],\n",
    "    'Training Time (s)': [results['Random Forest']['train_time'], sklearn_train_time]\n",
    "})\n",
    "\n",
    "display(Markdown(\"### ğŸ“Š Resultados de la ComparaciÃ³n\"))\n",
    "display(comparison_df)\n",
    "\n",
    "# Ventajas de MLPY\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"background-color: #fff3e0; padding: 15px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <h4>ğŸŒŸ Ventajas de MLPY Demostradas</h4>\n",
    "    <ul>\n",
    "        <li>âœ… <b>API Unificada:</b> Misma interfaz para todos los modelos</li>\n",
    "        <li>âœ… <b>ValidaciÃ³n Integrada:</b> DetecciÃ³n automÃ¡tica de problemas en datos</li>\n",
    "        <li>âœ… <b>Model Registry:</b> GestiÃ³n y versionado de modelos</li>\n",
    "        <li>âœ… <b>Ensemble FÃ¡cil:</b> CreaciÃ³n trivial de mÃ©todos ensemble</li>\n",
    "        <li>âœ… <b>Resampling Nativo:</b> Cross-validation integrado</li>\n",
    "        <li>âœ… <b>Sistema de Medidas Rico:</b> MÃºltiples mÃ©tricas con agregaciÃ³n</li>\n",
    "        <li>âœ… <b>AbstracciÃ³n de Tareas:</b> CÃ³digo mÃ¡s limpio y mantenible</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con todos los resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()) + ['Baseline'],\n",
    "    'MSE': [r['mse'] for r in results.values()] + [baseline_mse],\n",
    "    'MAE': [r['mae'] for r in results.values()] + [baseline_mae],\n",
    "    'Training Time (s)': [r['train_time'] for r in results.values()] + [baseline_train_time]\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values('MSE')\n",
    "\n",
    "# Crear visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. ComparaciÃ³n de MSE\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['#2ecc71' if m != 'Baseline' else '#e74c3c' for m in results_df['Model']]\n",
    "bars = ax1.barh(results_df['Model'], results_df['MSE'], color=colors)\n",
    "ax1.set_xlabel('Mean Squared Error', fontsize=12)\n",
    "ax1.set_title('ComparaciÃ³n de Rendimiento (MSE)', fontsize=14, fontweight='bold')\n",
    "ax1.axvline(x=baseline_mse, color='red', linestyle='--', alpha=0.5, label='Baseline')\n",
    "ax1.legend()\n",
    "\n",
    "# AÃ±adir valores en las barras\n",
    "for bar, val in zip(bars, results_df['MSE']):\n",
    "    ax1.text(bar.get_width(), bar.get_y() + bar.get_height()/2, \n",
    "             f'{val:.3f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# 2. Tiempo de entrenamiento\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(range(len(results_df)), results_df['Training Time (s)'], \n",
    "        color=['#3498db' if m != 'Baseline' else '#95a5a6' for m in results_df['Model']])\n",
    "ax2.set_xticks(range(len(results_df)))\n",
    "ax2.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax2.set_ylabel('Tiempo (segundos)', fontsize=12)\n",
    "ax2.set_title('Tiempo de Entrenamiento', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Actual vs Predicho (mejor modelo)\n",
    "ax3 = axes[1, 0]\n",
    "best_preds = results[results_df.iloc[0]['Model']]['predictions']\n",
    "ax3.scatter(best_preds.truth, best_preds.response, alpha=0.5, s=10)\n",
    "ax3.plot([0, 5], [0, 5], 'r--', lw=2, label='PredicciÃ³n perfecta')\n",
    "ax3.set_xlabel('Valores Reales', fontsize=12)\n",
    "ax3.set_ylabel('Valores Predichos', fontsize=12)\n",
    "ax3.set_title(f'Actual vs Predicho ({results_df.iloc[0][\"Model\"]})', fontsize=14, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Resultados de Cross-Validation\n",
    "ax4 = axes[1, 1]\n",
    "bp = ax4.boxplot(cv_scores, patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('#9b59b6')\n",
    "ax4.set_ylabel('MSE', fontsize=12)\n",
    "ax4.set_title('DistribuciÃ³n 5-Fold Cross-Validation', fontsize=14, fontweight='bold')\n",
    "ax4.axhline(y=cv_mean, color='red', linestyle='--', \n",
    "            label=f'Media: {cv_mean:.4f}')\n",
    "ax4.axhline(y=cv_mean + cv_std, color='orange', linestyle=':', alpha=0.5)\n",
    "ax4.axhline(y=cv_mean - cv_std, color='orange', linestyle=':', alpha=0.5, \n",
    "            label=f'Â±1 std: {cv_std:.4f}')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('MLPY Framework - AnÃ¡lisis de Resultados', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla resumen de resultados\n",
    "display(Markdown(\"### ğŸ“‹ Ranking Final de Modelos\"))\n",
    "\n",
    "# Calcular mejoras\n",
    "results_df['Improvement vs Baseline (%)'] = \\\n",
    "    ((baseline_mse - results_df['MSE']) / baseline_mse * 100).round(1)\n",
    "\n",
    "# Estilizar DataFrame\n",
    "styled_df = results_df.style.background_gradient(subset=['MSE'], cmap='RdYlGn_r') \\\n",
    "                           .background_gradient(subset=['MAE'], cmap='RdYlGn_r') \\\n",
    "                           .background_gradient(subset=['Improvement vs Baseline (%)'], cmap='RdYlGn') \\\n",
    "                           .format({'MSE': '{:.4f}', \n",
    "                                   'MAE': '{:.4f}', \n",
    "                                   'Training Time (s)': '{:.3f}',\n",
    "                                   'Improvement vs Baseline (%)': '{:.1f}%'})\n",
    "\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Conclusiones\n",
    "\n",
    "### ğŸ“Š Resultados Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estadÃ­sticas finales\n",
    "best_mse = results_df.iloc[0]['MSE']\n",
    "best_model = results_df.iloc[0]['Model']\n",
    "improvement = ((baseline_mse - best_mse) / baseline_mse) * 100\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<div style=\"background-color: #d4edda; padding: 20px; border-radius: 10px; border-left: 5px solid #28a745;\">\n",
    "    <h3>ğŸ† Resumen de Resultados</h3>\n",
    "    <table style=\"width: 100%; font-size: 14px;\">\n",
    "        <tr>\n",
    "            <td><b>Mejor Modelo:</b></td>\n",
    "            <td>{best_model}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>MSE Final:</b></td>\n",
    "            <td>{best_mse:.4f}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>Mejora vs Baseline:</b></td>\n",
    "            <td>{improvement:.1f}%</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>CV MSE (Â±std):</b></td>\n",
    "            <td>{cv_mean:.4f} Â± {cv_std:.4f}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>Modelos Evaluados:</b></td>\n",
    "            <td>{len(results)}</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Puntos Clave Demostrados\n",
    "\n",
    "1. **ğŸ¯ API Unificada**: MLPY proporciona una interfaz consistente para todos los modelos\n",
    "2. **ğŸ” ValidaciÃ³n AutomÃ¡tica**: DetecciÃ³n proactiva de problemas en los datos\n",
    "3. **ğŸ“š Model Registry**: GestiÃ³n profesional de modelos con versionado\n",
    "4. **ğŸ­ Ensemble Methods**: CreaciÃ³n simple de modelos ensemble complejos\n",
    "5. **ğŸ“Š EvaluaciÃ³n Robusta**: Cross-validation y mÃºltiples mÃ©tricas integradas\n",
    "6. **âš¡ Rendimiento**: Comparable o superior a implementaciones directas\n",
    "7. **ğŸ”§ Extensibilidad**: FÃ¡cil integraciÃ³n con el ecosistema Python ML\n",
    "\n",
    "### ğŸš€ PrÃ³ximos Pasos\n",
    "\n",
    "- **AutoML**: Explorar capacidades de optimizaciÃ³n automÃ¡tica\n",
    "- **Deep Learning**: Integrar modelos de redes neuronales\n",
    "- **Feature Engineering**: Pipeline automatizado de transformaciÃ³n\n",
    "- **MLOps**: Deployment y monitoreo en producciÃ³n\n",
    "- **Distributed Training**: Escalar a datasets mÃ¡s grandes\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Recursos\n",
    "\n",
    "- ğŸ“– [DocumentaciÃ³n Completa](../docs/DOCUMENTATION_SUMMARY.md)\n",
    "- ğŸ“ [Tutoriales](../docs/tutoriales/00_INDICE_TUTORIALES.md)\n",
    "- ğŸ’» [GitHub Repository](https://github.com/your-org/mlpy)\n",
    "- ğŸ“§ [Contacto](mailto:mlpy@example.com)\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Gracias por explorar MLPY Framework! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}